Source: https://developer.apple.com/documentation/CreateML/MLSoundClassifier

[ Skip Navigation ](https://developer.apple.com/documentation/CreateML/MLSoundClassifier#app-main)
  * [Global Nav Open Menu](https://developer.apple.com/documentation/CreateML/MLSoundClassifier#ac-gn-menustate)[Global Nav Close Menu](https://developer.apple.com/documentation/CreateML/MLSoundClassifier)
  * [Apple Developer](https://developer.apple.com/)


[ Search Developer Cancel  ](https://developer.apple.com/search/)
  * [Apple Developer](https://developer.apple.com/)
  * [News](https://developer.apple.com/news/)
  * [Discover](https://developer.apple.com/discover/)
  * [Design](https://developer.apple.com/design/)
  * [Develop](https://developer.apple.com/develop/)
  * [Distribute](https://developer.apple.com/distribute/)
  * [Support](https://developer.apple.com/support/)
  * [Account](https://developer.apple.com/account/)
  * [](https://developer.apple.com/search/)


Cancel 
Only search within “Documentation”
### Quick Links
  * [Downloads](https://developer.apple.com/download/)
  * [Documentation](https://developer.apple.com/documentation/)
  * [Sample Code](https://developer.apple.com/documentation/samplecode/)
  * [Videos](https://developer.apple.com/videos/)
  * [Forums](https://developer.apple.com/forums/)

5 Quick Links
[ Documentation ](https://developer.apple.com/documentation)
[ Open Menu ](https://developer.apple.com/documentation/CreateML/MLSoundClassifier)
  * SwiftLanguage: Swift


[](https://developer.apple.com/documentation/CreateML/MLSoundClassifier)
## [ Create ML  ](https://developer.apple.com/documentation/createml)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
M
11 of 35 symbols inside 1196781824 [init(trainingData:parameters:)](https://developer.apple.com/documentation/createml/mlsoundclassifier/init\(trainingdata:parameters:\))
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
13 of 58 symbols inside <root> [Creating a text classifier model](https://developer.apple.com/documentation/createml/creating-a-text-classifier-model)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
14 of 58 symbols inside <root> [Creating a word tagger model](https://developer.apple.com/documentation/createml/creating-a-word-tagger-model)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
S
15 of 58 symbols inside <root> containing 31 symbols[MLTextClassifier](https://developer.apple.com/documentation/createml/mltextclassifier)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
S
16 of 58 symbols inside <root> containing 31 symbols[MLWordTagger](https://developer.apple.com/documentation/createml/mlwordtagger)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
S
17 of 58 symbols inside <root> containing 22 symbols[MLGazetteer](https://developer.apple.com/documentation/createml/mlgazetteer)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
S
18 of 58 symbols inside <root> containing 24 symbols[MLWordEmbedding](https://developer.apple.com/documentation/createml/mlwordembedding)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
19 of 58 symbols inside <root>
Sound models
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
S
20 of 58 symbols inside <root> containing 35 symbols[MLSoundClassifier](https://developer.apple.com/documentation/createml/mlsoundclassifier)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
1 of 35 symbols inside 1196781824 
Training a sound classifier asynchronously
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
M
2 of 35 symbols inside 1196781824 [static train(trainingData:parameters:sessionParameters:)](https://developer.apple.com/documentation/createml/mlsoundclassifier/train\(trainingdata:parameters:sessionparameters:\))
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
M
3 of 35 symbols inside 1196781824 [static func makeTrainingSession(trainingData: MLSoundClassifier.DataSource, parameters: MLSoundClassifier.ModelParameters, sessionParameters: MLTrainingSessionParameters) throws -> MLTrainingSession<MLSoundClassifier>](https://developer.apple.com/documentation/createml/mlsoundclassifier/maketrainingsession\(trainingdata:parameters:sessionparameters:\))
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
M
4 of 35 symbols inside 1196781824 [static func resume(MLTrainingSession<MLSoundClassifier>) throws -> MLJob<MLSoundClassifier>](https://developer.apple.com/documentation/createml/mlsoundclassifier/resume\(_:\))
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
M
5 of 35 symbols inside 1196781824 [static func restoreTrainingSession(sessionParameters: MLTrainingSessionParameters) throws -> MLTrainingSession<MLSoundClassifier>](https://developer.apple.com/documentation/createml/mlsoundclassifier/restoretrainingsession\(sessionparameters:\))
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
M
6 of 35 symbols inside 1196781824 [static func extractFeatures(trainingData: MLSoundClassifier.DataSource, parameters: MLSoundClassifier.FeatureExtractionParameters, sessionParameters: MLTrainingSessionParameters) throws -> MLJob<MLSoundClassifier.DataSource>](https://developer.apple.com/documentation/createml/mlsoundclassifier/extractfeatures\(trainingdata:parameters:sessionparameters:\))
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
S
7 of 35 symbols inside 1196781824 containing 7 symbols[MLSoundClassifier.FeatureExtractionParameters](https://developer.apple.com/documentation/createml/mlsoundclassifier/featureextractionparameters)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
8 of 35 symbols inside 1196781824 
Creating a sound classifier from a checkpoint
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
M
9 of 35 symbols inside 1196781824 [init(checkpoint: MLCheckpoint) throws](https://developer.apple.com/documentation/createml/mlsoundclassifier/init\(checkpoint:\))
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
10 of 35 symbols inside 1196781824 
Training a sound classifier synchronously
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
M
11 of 35 symbols inside 1196781824 [init(trainingData:parameters:)](https://developer.apple.com/documentation/createml/mlsoundclassifier/init\(trainingdata:parameters:\))
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
12 of 35 symbols inside 1196781824 
Evaluating a sound classifier
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
M
13 of 35 symbols inside 1196781824 [func evaluation(on:)](https://developer.apple.com/documentation/createml/mlsoundclassifier/evaluation\(on:\))
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
P
14 of 35 symbols inside 1196781824 [var trainingMetrics: MLClassifierMetrics](https://developer.apple.com/documentation/createml/mlsoundclassifier/trainingmetrics)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
P
15 of 35 symbols inside 1196781824 [var validationMetrics: MLClassifierMetrics](https://developer.apple.com/documentation/createml/mlsoundclassifier/validationmetrics)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
16 of 35 symbols inside 1196781824 
Testing a sound classifier
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
M
17 of 35 symbols inside 1196781824 [func predictions(from: [URL]) throws -> [String]](https://developer.apple.com/documentation/createml/mlsoundclassifier/predictions\(from:\))
93 items were found. Tab back to navigate through them. 
/ 
Navigator is ready 
  * [ Create ML ](https://developer.apple.com/documentation/createml)
  * [ MLSoundClassifier ](https://developer.apple.com/documentation/CreateML/MLSoundClassifier)
  *     * MLSoundClassifier 


Structure
# MLSoundClassifier
A machine learning model you train with audio files to recognize and identify sounds on a device.
iOS 15.0+iPadOS 15.0+Mac Catalyst 15.0+macOS 10.15+visionOS 1.0+
```
struct MLSoundClassifier
```

## [Overview](https://developer.apple.com/documentation/CreateML/MLSoundClassifier#overview)
A sound classifier is a machine learning model that identifies and categorizes sounds in an app. Create a sound classifier by gathering a dataset of audio files and use them to train a model with [`MLSoundClassifier`](https://developer.apple.com/documentation/createml/mlsoundclassifier).
Assemble an audio dataset by recording or gathering audio files that best represent the sounds you want your app to identify. Additionally, create a _negative class_ — a group of related noises the sound classifier might hear but aren’t relevant — by collecting or recording example sounds.
For example, say you’re creating a sound classifier to identify laughter and applause. In addition to gathering audio examples of people laughing and clapping, you can add an additional category for background noise. By adding recordings from various settings, such as theaters and amphitheaters, your sound classifier can distinguish the sounds of interest from environmental noises. In other words, the sound classifier won’t predict “Applause” when there isn’t any. Like any classifier, when you request a prediction, a sound classifier always returns one of the categories it learned from a training dataset.
Gather at least 10 audio examples of each sound category you want the sound classifier to learn, plus at least one negative class for background noise. The audio examples can be in any file format that Core Audio supports, including:
  * M4A
  * MP3
  * AIFF
  * WAV


Tip
Use single-channel audio files with a sample rate of 16 kHz or higher for best results.
Reduce a sound classifier’s bias — which can adversely affect its performance — by gathering audio files that use a consistent bit depth and sample rate.
Train, evaluate, and export your sound classifier by following similar steps to creating any other Create ML model type. For more information about the Create ML training workflow, see:
  * [Creating an Image Classifier Model](https://developer.apple.com/documentation/createml/creating-an-image-classifier-model)
  * [Creating an Action Classifier Model](https://developer.apple.com/documentation/createml/creating-an-action-classifier-model)


Add the sound classifier’s Core ML model to an Xcode project and use it to create an [`SNClassifySoundRequest`](https://developer.apple.com/documentation/SoundAnalysis/SNClassifySoundRequest) at runtime. Your app uses the sound request to identify sounds in an audio file or audio stream by following the steps in the following articles, respectively:
  * [Classifying Sounds in an Audio File](https://developer.apple.com/documentation/SoundAnalysis/classifying-sounds-in-an-audio-file)
  * [Classifying Sounds in an Audio Stream](https://developer.apple.com/documentation/SoundAnalysis/classifying-sounds-in-an-audio-stream)


## [Topics](https://developer.apple.com/documentation/CreateML/MLSoundClassifier#topics)
### [Training a sound classifier asynchronously](https://developer.apple.com/documentation/CreateML/MLSoundClassifier#Training-a-sound-classifier-asynchronously)
[`static train(trainingData:parameters:sessionParameters:)`](https://developer.apple.com/documentation/createml/mlsoundclassifier/train\(trainingdata:parameters:sessionparameters:\))
Begins an asynchronous sound classifier training session with a training dataset represented by a data source.
[`static func makeTrainingSession(trainingData: MLSoundClassifier.DataSource, parameters: MLSoundClassifier.ModelParameters, sessionParameters: MLTrainingSessionParameters) throws -> MLTrainingSession<MLSoundClassifier>`](https://developer.apple.com/documentation/createml/mlsoundclassifier/maketrainingsession\(trainingdata:parameters:sessionparameters:\))
Creates an asynchronous training session for a sound classifier.
[`static func resume(MLTrainingSession<MLSoundClassifier>) throws -> MLJob<MLSoundClassifier>`](https://developer.apple.com/documentation/createml/mlsoundclassifier/resume\(_:\))
Begins or continues an asynchronous training session for a sound classifier.
[`static func restoreTrainingSession(sessionParameters: MLTrainingSessionParameters) throws -> MLTrainingSession<MLSoundClassifier>`](https://developer.apple.com/documentation/createml/mlsoundclassifier/restoretrainingsession\(sessionparameters:\))
Creates an asynchronous training session for a sound classifier by restoring an existing training session’s state from its parameters.
[`static func extractFeatures(trainingData: MLSoundClassifier.DataSource, parameters: MLSoundClassifier.FeatureExtractionParameters, sessionParameters: MLTrainingSessionParameters) throws -> MLJob<MLSoundClassifier.DataSource>`](https://developer.apple.com/documentation/createml/mlsoundclassifier/extractfeatures\(trainingdata:parameters:sessionparameters:\))
Begins an asynchronous session that extracts sound features from a data source of sound files.
[`struct FeatureExtractionParameters`](https://developer.apple.com/documentation/createml/mlsoundclassifier/featureextractionparameters)
Parameters that affect the process of extracting sound features from audio files.
### [Creating a sound classifier from a checkpoint](https://developer.apple.com/documentation/CreateML/MLSoundClassifier#Creating-a-sound-classifier-from-a-checkpoint)
[`init(checkpoint: MLCheckpoint) throws`](https://developer.apple.com/documentation/createml/mlsoundclassifier/init\(checkpoint:\))
Creates a sound classifier from a training session checkpoint.
### [Training a sound classifier synchronously](https://developer.apple.com/documentation/CreateML/MLSoundClassifier#Training-a-sound-classifier-synchronously)
[`init(trainingData:parameters:)`](https://developer.apple.com/documentation/createml/mlsoundclassifier/init\(trainingdata:parameters:\))
Creates a sound classifier with a training dataset represented by a data source.
### [Evaluating a sound classifier](https://developer.apple.com/documentation/CreateML/MLSoundClassifier#Evaluating-a-sound-classifier)
[`func evaluation(on:)`](https://developer.apple.com/documentation/createml/mlsoundclassifier/evaluation\(on:\))
Generates metrics by evaluating the sound classifier’s performance on a dataset represented by a data source.
[`var trainingMetrics: MLClassifierMetrics`](https://developer.apple.com/documentation/createml/mlsoundclassifier/trainingmetrics)
Measurements of the classifier’s performance on the training data set.
[`var validationMetrics: MLClassifierMetrics`](https://developer.apple.com/documentation/createml/mlsoundclassifier/validationmetrics)
Measurements of the image classifier’s performance on the validation dataset.
### [Testing a sound classifier](https://developer.apple.com/documentation/CreateML/MLSoundClassifier#Testing-a-sound-classifier)
[`func predictions(from: [URL]) throws -> [String]`](https://developer.apple.com/documentation/createml/mlsoundclassifier/predictions\(from:\))
Generates predictions for an array of audio files.
[`func predictions(from: [URL], overlapFactor: Double, predictionTimeWindowSize: TimeInterval) throws -> [String]`](https://developer.apple.com/documentation/createml/mlsoundclassifier/predictions\(from:overlapfactor:predictiontimewindowsize:\))
Generates predictions that use an overlap factor and time window size for an array of audio files.
### [Saving a sound classifier](https://developer.apple.com/documentation/CreateML/MLSoundClassifier#Saving-a-sound-classifier)
[`func write(to: URL, metadata: MLModelMetadata?) throws`](https://developer.apple.com/documentation/createml/mlsoundclassifier/write\(to:metadata:\))
Exports the sound classifier as a model file to a location in the file system.
[`func write(toFile: String, metadata: MLModelMetadata?) throws`](https://developer.apple.com/documentation/createml/mlsoundclassifier/write\(tofile:metadata:\))
Exports the sound classifier as a model file to a path in the file system.
### [Inspecting a sound classifier model](https://developer.apple.com/documentation/CreateML/MLSoundClassifier#Inspecting-a-sound-classifier-model)
[`var model: MLModel`](https://developer.apple.com/documentation/createml/mlsoundclassifier/model)
The underlying model instance of the sound classifier stored in memory.
[`let modelParameters: MLSoundClassifier.ModelParameters`](https://developer.apple.com/documentation/createml/mlsoundclassifier/modelparameters-swift.property)
The model configuration parameters the sound classifier used during its training session.
### [Describing a sound classifier](https://developer.apple.com/documentation/CreateML/MLSoundClassifier#Describing-a-sound-classifier)
[`var description: String`](https://developer.apple.com/documentation/createml/mlsoundclassifier/description)
A text representation of the sound classifier.
[`var debugDescription: String`](https://developer.apple.com/documentation/createml/mlsoundclassifier/debugdescription)
A text representation of the sound classifier that’s suitable for output during debugging.
[`var playgroundDescription: Any`](https://developer.apple.com/documentation/createml/mlsoundclassifier/playgrounddescription)
A description of the sound classifier in a playground.
### [Supporting types](https://developer.apple.com/documentation/CreateML/MLSoundClassifier#Supporting-types)
[`enum DataSource`](https://developer.apple.com/documentation/createml/mlsoundclassifier/datasource)
A representation of a sound-classifier dataset located in the file system or in a data table.
[`struct ModelParameters`](https://developer.apple.com/documentation/createml/mlsoundclassifier/modelparameters-swift.struct)
Parameters that affect the process of training a sound-classifier model.
### [Default Implementations](https://developer.apple.com/documentation/CreateML/MLSoundClassifier#Default-Implementations)
[API Reference CustomDebugStringConvertible Implementations](https://developer.apple.com/documentation/createml/mlsoundclassifier/customdebugstringconvertible-implementations)
[API Reference CustomPlaygroundDisplayConvertible Implementations](https://developer.apple.com/documentation/createml/mlsoundclassifier/customplaygrounddisplayconvertible-implementations)
[API Reference CustomStringConvertible Implementations](https://developer.apple.com/documentation/createml/mlsoundclassifier/customstringconvertible-implementations)
## [Relationships](https://developer.apple.com/documentation/CreateML/MLSoundClassifier#relationships)
### [Conforms To](https://developer.apple.com/documentation/CreateML/MLSoundClassifier#conforms-to)
  * [`Copyable`](https://developer.apple.com/documentation/Swift/Copyable)
  * [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
  * [`CustomPlaygroundDisplayConvertible`](https://developer.apple.com/documentation/Swift/CustomPlaygroundDisplayConvertible)
  * [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
  * [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
  * [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)


Current page is MLSoundClassifier 
[Apple](https://www.apple.com)
  1. [Developer](https://developer.apple.com/)
  2. [ Documentation ](https://developer.apple.com/documentation/)


###  Platforms 
Toggle Menu 
  * [iOS](https://developer.apple.com/ios/)
  * [iPadOS](https://developer.apple.com/ipados/)
  * [macOS](https://developer.apple.com/macos/)
  * [tvOS](https://developer.apple.com/tvos/)
  * [visionOS](https://developer.apple.com/visionos/)
  * [watchOS](https://developer.apple.com/watchos/)


###  Tools 
Toggle Menu 
  * [Swift](https://developer.apple.com/swift/)
  * [SwiftUI](https://developer.apple.com/swiftui/)
  * [Swift Playground](https://developer.apple.com/swift-playground/)
  * [TestFlight](https://developer.apple.com/testflight/)
  * [Xcode](https://developer.apple.com/xcode/)
  * [Xcode Cloud](https://developer.apple.com/xcode-cloud/)
  * [SF Symbols](https://developer.apple.com/sf-symbols/)


###  Topics & Technologies 
Toggle Menu 
  * [Accessibility](https://developer.apple.com/accessibility/)
  * [Accessories](https://developer.apple.com/accessories/)
  * [App Extension](https://developer.apple.com/app-extensions/)
  * [App Store](https://developer.apple.com/app-store/)
  * [Audio & Video](https://developer.apple.com/audio/)
  * [Augmented Reality](https://developer.apple.com/augmented-reality/)
  * [Design](https://developer.apple.com/design/)
  * [Distribution](https://developer.apple.com/distribute/)
  * [Education](https://developer.apple.com/education/)
  * [Fonts](https://developer.apple.com/fonts/)
  * [Games](https://developer.apple.com/games/)
  * [Health & Fitness](https://developer.apple.com/health-fitness/)
  * [In-App Purchase](https://developer.apple.com/in-app-purchase/)
  * [Localization](https://developer.apple.com/localization/)
  * [Maps & Location](https://developer.apple.com/maps/)
  * [Machine Learning & AI](https://developer.apple.com/machine-learning/)
  * [Open Source](https://opensource.apple.com/)
  * [Security](https://developer.apple.com/security/)
  * [Safari & Web](https://developer.apple.com/safari/)


###  Resources 
Toggle Menu 
  *   * [Documentation](https://developer.apple.com/documentation/)
  * [Tutorials](https://developer.apple.com/learn/)
  * [Downloads](https://developer.apple.com/download/)
  * [Forums](https://developer.apple.com/forums/)
  * [Videos](https://developer.apple.com/videos/)


###  Support 
Toggle Menu 
  * [Support Articles](https://developer.apple.com/support/articles/)
  * [Contact Us](https://developer.apple.com/contact/)
  * [Bug Reporting](https://developer.apple.com/bug-reporting/)
  * [System Status](https://developer.apple.com/system-status/)


###  Account 
Toggle Menu 
  * [Apple Developer](https://developer.apple.com/account/)
  * [App Store Connect](https://appstoreconnect.apple.com/)
  * [Certificates, IDs, & Profiles](https://developer.apple.com/account/ios/certificate/)
  * [Feedback Assistant](https://feedbackassistant.apple.com/)


###  Programs 
Toggle Menu 
  * [Apple Developer Program](https://developer.apple.com/programs/)
  * [Apple Developer Enterprise Program](https://developer.apple.com/programs/enterprise/)
  * [App Store Small Business Program](https://developer.apple.com/app-store/small-business-program/)
  * [MFi Program](https://mfi.apple.com/)
  * [News Partner Program](https://developer.apple.com/programs/news-partner/)
  * [Video Partner Program](https://developer.apple.com/programs/video-partner/)
  * [Security Bounty Program](https://developer.apple.com/security-bounty/)
  * [Security Research Device Program](https://developer.apple.com/programs/security-research-device/)


###  Events 
Toggle Menu 
  * [Meet with Apple](https://developer.apple.com/events/)
  * [Apple Developer Centers](https://developer.apple.com/events/developer-centers/)
  * [App Store Awards](https://developer.apple.com/app-store/app-store-awards/)
  * [Apple Design Awards](https://developer.apple.com/design/awards/)
  * [Apple Developer Academies](https://developer.apple.com/academies/)
  * [WWDC](https://developer.apple.com/wwdc/)


To submit feedback on documentation, visit [Feedback Assistant](applefeedback://new?form_identifier=developertools.fba&answers%5B%3Aarea%5D=seedADC%3Adevpubs&answers%5B%3Adoc_type_req%5D=Technology%20Documentation&answers%5B%3Adocumentation_link_req%5D=https%3A%2F%2Fdeveloper.apple.com%2Fdocumentation%2FCreateML%2FMLSoundClassifier).
Select a color scheme preference
Light
Dark
Auto
Copyright © 2025 [Apple Inc.](https://www.apple.com) All rights reserved. 
[ Terms of Use ](https://www.apple.com/legal/internet-services/terms/site.html)[ Privacy Policy ](https://www.apple.com/legal/privacy/)[ Agreements and Guidelines ](https://developer.apple.com/support/terms/)
