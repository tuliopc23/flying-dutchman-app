Source: https://developer.apple.com/documentation/coreml/understanding-a-dice-roll-with-vision-and-object-detection

[ Skip Navigation ](https://developer.apple.com/documentation/coreml/understanding-a-dice-roll-with-vision-and-object-detection#app-main)
  * [Global Nav Open Menu](https://developer.apple.com/documentation/coreml/understanding-a-dice-roll-with-vision-and-object-detection#ac-gn-menustate)[Global Nav Close Menu](https://developer.apple.com/documentation/coreml/understanding-a-dice-roll-with-vision-and-object-detection)
  * [Apple Developer](https://developer.apple.com/)


[ Search Developer Cancel  ](https://developer.apple.com/search/)
  * [Apple Developer](https://developer.apple.com/)
  * [News](https://developer.apple.com/news/)
  * [Discover](https://developer.apple.com/discover/)
  * [Design](https://developer.apple.com/design/)
  * [Develop](https://developer.apple.com/develop/)
  * [Distribute](https://developer.apple.com/distribute/)
  * [Support](https://developer.apple.com/support/)
  * [Account](https://developer.apple.com/account/)
  * [](https://developer.apple.com/search/)


Cancel 
Only search within “Documentation”
### Quick Links
  * [Downloads](https://developer.apple.com/download/)
  * [Documentation](https://developer.apple.com/documentation/)
  * [Sample Code](https://developer.apple.com/documentation/samplecode/)
  * [Videos](https://developer.apple.com/videos/)
  * [Forums](https://developer.apple.com/forums/)

5 Quick Links
[ Documentation ](https://developer.apple.com/documentation)
[ Open Menu ](https://developer.apple.com/documentation/coreml/understanding-a-dice-roll-with-vision-and-object-detection)
  * SwiftLanguage:  Swift  Objective-C 
Language: 
    * Swift 
    * [ Objective-C ](https://developer.apple.com/documentation/coreml/understanding-a-dice-roll-with-vision-and-object-detection)


[](https://developer.apple.com/documentation/coreml/understanding-a-dice-roll-with-vision-and-object-detection)
## [ Core ML  ](https://developer.apple.com/documentation/coreml)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
27 of 54 symbols inside <root> containing 2 symbols[MLNeuralEngineComputeDevice](https://developer.apple.com/documentation/coreml/mlneuralenginecomputedevice)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
18 of 54 symbols inside <root> [Downloading and Compiling a Model on the User’s Device](https://developer.apple.com/documentation/coreml/downloading-and-compiling-a-model-on-the-user-s-device)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
Collection
19 of 54 symbols inside <root> containing 9 symbols[Model Integration Samples](https://developer.apple.com/documentation/coreml/model-integration-samples)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
1 of 9 symbols inside 1345615585 
Tabular data models
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
2 of 9 symbols inside 1345615585 [Integrating a Core ML Model into Your App](https://developer.apple.com/documentation/coreml/integrating-a-core-ml-model-into-your-app)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
3 of 9 symbols inside 1345615585 
Image classification models
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
4 of 9 symbols inside 1345615585 [Using Core ML for semantic image segmentation](https://developer.apple.com/documentation/coreml/using-core-ml-for-semantic-image-segmentation)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
5 of 9 symbols inside 1345615585 [Classifying Images with Vision and Core ML](https://developer.apple.com/documentation/coreml/classifying-images-with-vision-and-core-ml)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
6 of 9 symbols inside 1345615585 [Detecting human body poses in an image](https://developer.apple.com/documentation/coreml/detecting-human-body-poses-in-an-image)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
7 of 9 symbols inside 1345615585 [Understanding a Dice Roll with Vision and Object Detection](https://developer.apple.com/documentation/coreml/understanding-a-dice-roll-with-vision-and-object-detection)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
8 of 9 symbols inside 1345615585 
Text classification models
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
9 of 9 symbols inside 1345615585 [Finding answers to questions in a text document](https://developer.apple.com/documentation/coreml/finding-answers-to-questions-in-a-text-document)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
20 of 54 symbols inside <root>
Model encryption
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
21 of 54 symbols inside <root> [Generating a Model Encryption Key](https://developer.apple.com/documentation/coreml/generating-a-model-encryption-key)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
22 of 54 symbols inside <root> [Encrypting a Model in Your App](https://developer.apple.com/documentation/coreml/encrypting-a-model-in-your-app)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
23 of 54 symbols inside <root>
Compute devices
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
E
24 of 54 symbols inside <root> containing 6 symbols[MLComputeDevice](https://developer.apple.com/documentation/coreml/mlcomputedevice)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
25 of 54 symbols inside <root> [MLCPUComputeDevice](https://developer.apple.com/documentation/coreml/mlcpucomputedevice)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
26 of 54 symbols inside <root> containing 2 symbols[MLGPUComputeDevice](https://developer.apple.com/documentation/coreml/mlgpucomputedevice)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
27 of 54 symbols inside <root> containing 2 symbols[MLNeuralEngineComputeDevice](https://developer.apple.com/documentation/coreml/mlneuralenginecomputedevice)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
rP
28 of 54 symbols inside <root> [MLComputeDeviceProtocol](https://developer.apple.com/documentation/coreml/mlcomputedeviceprotocol)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
29 of 54 symbols inside <root>
Compute plan
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
30 of 54 symbols inside <root> containing 13 symbols[MLComputePlan](https://developer.apple.com/documentation/coreml/mlcomputeplan-1w21n)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
E
31 of 54 symbols inside <root> containing 11 symbols[MLModelStructure](https://developer.apple.com/documentation/coreml/mlmodelstructure-swift.enum)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
S
32 of 54 symbols inside <root> containing 8 symbols[MLComputePolicy](https://developer.apple.com/documentation/coreml/mlcomputepolicy)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
33 of 54 symbols inside <root> [func withMLTensorComputePolicy<R>(MLComputePolicy, () async throws -> R) async rethrows -> R](https://developer.apple.com/documentation/coreml/withmltensorcomputepolicy\(_:_:\)-8stx9)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
34 of 54 symbols inside <root> [func withMLTensorComputePolicy<Result>(MLComputePolicy, () throws -> Result) rethrows -> Result](https://developer.apple.com/documentation/coreml/withmltensorcomputepolicy\(_:_:\)-6z33x)
63 items were found. Tab back to navigate through them. 
/ 
Navigator is ready 
  * [ Core ML ](https://developer.apple.com/documentation/coreml)
  * [ Model Integration Samples ](https://developer.apple.com/documentation/coreml/model-integration-samples)
  * [ Understanding a Dice Roll with Vision and Object Detection ](https://developer.apple.com/documentation/coreml/understanding-a-dice-roll-with-vision-and-object-detection)
  *     * [ Model Integration Samples ](https://developer.apple.com/documentation/coreml/model-integration-samples)
    * Understanding a Dice Roll with Vision and Object Detection 


Sample Code
# Understanding a Dice Roll with Vision and Object Detection
Detect dice position and values shown in a camera frame, and determine the end of a roll by leveraging a dice detection model.
[ Download ](https://docs-assets.developer.apple.com/published/637284ef8498/UnderstandingADiceRollWithVisionAndObjectDetection.zip)
iOS 13.0+iPadOS 13.0+Xcode 12.0+iPad 13.0+
## [Overview](https://developer.apple.com/documentation/coreml/understanding-a-dice-roll-with-vision-and-object-detection#Overview)
This sample app uses an object detection model trained with [Create ML](https://developer.apple.com/documentation/CreateML) to recognize the tops of dice and their values when the dice roll onto a flat surface.
After you run the object detection model on camera frames through [Vision](https://developer.apple.com/documentation/Vision), the model interprets the result to identify when a roll has ended and what values the dice show.
Note
This sample code project is associated with WWDC 2019 session [228: Creating Great Apps Using Core ML and ARKit](https://developer.apple.com/videos/play/wwdc19/228/).
### [Configure the sample code project](https://developer.apple.com/documentation/coreml/understanding-a-dice-roll-with-vision-and-object-detection#Configure-the-sample-code-project)
Before you run the sample code project in Xcode, note the following:
  * You must run this sample code project on a physical device that uses iOS 13 or later. The project doesn’t work with Simulator.
  * The model works best on white dice with black pips. It may perform differently on dice that use other colors.


### [Add inputs to the request](https://developer.apple.com/documentation/coreml/understanding-a-dice-roll-with-vision-and-object-detection#Add-inputs-to-the-request)
In Vision, beginning in iOS 13, you can provide inputs other than images to a model by attaching an [`MLFeatureProvider`](https://developer.apple.com/documentation/CoreML/MLFeatureProvider) object to your model. This is useful in the case of object detection when you want to specify different thresholds than the defaults.
As shown below, a feature provider can provide values for the `iouThreshold` and `confidenceThreshold` inputs to your object detection model.
To use this threshold provider with your [`VNCoreMLModel`](https://developer.apple.com/documentation/Vision/VNCoreMLModel), assign it to the [`featureProvider`](https://developer.apple.com/documentation/Vision/VNCoreMLModel/featureProvider) property of your [`VNCoreMLModel`](https://developer.apple.com/documentation/Vision/VNCoreMLModel) as seen in the following example.
### [Set up a Vision request to handle camera frames](https://developer.apple.com/documentation/coreml/understanding-a-dice-roll-with-vision-and-object-detection#Set-up-a-Vision-request-to-handle-camera-frames)
For simplicity, you can use camera frames coming from an [`ARSession`](https://developer.apple.com/documentation/ARKit/ARSession).
To run your detector on these frames, first set up a [`VNCoreMLRequest`](https://developer.apple.com/documentation/Vision/VNCoreMLRequest) request with your model, as shown in the example below.
### [Pass camera frames to the object detector to predict dice locations](https://developer.apple.com/documentation/coreml/understanding-a-dice-roll-with-vision-and-object-detection#Pass-camera-frames-to-the-object-detector-to-predict-dice-locations)
Pass the frames from the camera to the [`VNCoreMLRequest`](https://developer.apple.com/documentation/Vision/VNCoreMLRequest) so it can make predictions using a [`VNImageRequestHandler`](https://developer.apple.com/documentation/Vision/VNImageRequestHandler) object. The [`VNImageRequestHandler`](https://developer.apple.com/documentation/Vision/VNImageRequestHandler) object handles image resizing and preprocessing as well as post-processing of your model’s outputs for every prediction.
To pass camera frames to your model, you first need to find the image orientation that corresponds to your device’s physical orientation. If the device’s orientation changes, the aspect ratio of the images can also change. Because you need to scale the bounding boxes for the detected objects back to your original image, you need to keep track of its size.
Finally, you invoke the [`VNImageRequestHandler`](https://developer.apple.com/documentation/Vision/VNImageRequestHandler) with the image from the camera and information about the current orientation to make a prediction using your object detector.
Now that the app handles providing _input_ data to your model, it’s time to interpret your model’s _output_.
### [Draw bounding boxes to understand your model’s behavior](https://developer.apple.com/documentation/coreml/understanding-a-dice-roll-with-vision-and-object-detection#Draw-bounding-boxes-to-understand-your-models-behavior)
You can get a better understanding of how well your detector performs by drawing bounding boxes around each object and its text label. The dice detection model detects the tops of dice and labels them according to the number of pips shown on each die’s top side.
To draw bounding boxes, see [Recognizing Objects in Live Capture](https://developer.apple.com/documentation/Vision/recognizing-objects-in-live-capture).
### [Determine wwhen a roll has ended](https://developer.apple.com/documentation/coreml/understanding-a-dice-roll-with-vision-and-object-detection#Determine-wwhen-a-roll-has-ended)
When playing a dice game, users want to know the result of a roll. The app determines that the roll has ended by waiting for the dice’s positions and values to stabilize.
You can define the requirements of an ended roll as a comparison between two consecutive camera frames with the following conditions:
  * The number of detected dice must be the same.
  * For each detected die:
    * The bounding box must have not moved.
    * The identified class must match.


Based on these constraints, you can make a function that tells the app whether a roll has ended based on the current and the previous [`VNRecognizedObjectObservation`](https://developer.apple.com/documentation/Vision/VNRecognizedObjectObservation) objects.
Now for every prediction (meaning every new camera frame) you can check whether the roll has ended.
### [Display the dice values](https://developer.apple.com/documentation/coreml/understanding-a-dice-roll-with-vision-and-object-detection#Display-the-dice-values)
Once the roll has ended, you can display the information on the screen or trigger some other behavior in the setting of a game.
This sample app shows the list of recognized values on screen, sorted from left-most to right-most [`VNRecognizedObjectObservation`](https://developer.apple.com/documentation/Vision/VNRecognizedObjectObservation). It sorts the values based on where the dice are on the surface according to each observation’s bounding box coordinates. The app does this by sorting the observations by their bounding box’s `centerX` property in ascending order.
## [See Also](https://developer.apple.com/documentation/coreml/understanding-a-dice-roll-with-vision-and-object-detection#see-also)
### [Image classification models](https://developer.apple.com/documentation/coreml/understanding-a-dice-roll-with-vision-and-object-detection#Image-classification-models)
[Using Core ML for semantic image segmentation](https://developer.apple.com/documentation/coreml/using-core-ml-for-semantic-image-segmentation)
Identify multiple objects in an image by using the DEtection TRansformer image-segmentation model.
[Classifying Images with Vision and Core ML](https://developer.apple.com/documentation/coreml/classifying-images-with-vision-and-core-ml)
Crop and scale photos using the Vision framework and classify them with a Core ML model.
[Detecting human body poses in an image](https://developer.apple.com/documentation/coreml/detecting-human-body-poses-in-an-image)
Locate people and the stance of their bodies by analyzing an image with a PoseNet model.
Current page is Understanding a Dice Roll with Vision and Object Detection 
[Apple](https://www.apple.com)
  1. [Developer](https://developer.apple.com/)
  2. [ Documentation ](https://developer.apple.com/documentation/)


###  Platforms 
Toggle Menu 
  * [iOS](https://developer.apple.com/ios/)
  * [iPadOS](https://developer.apple.com/ipados/)
  * [macOS](https://developer.apple.com/macos/)
  * [tvOS](https://developer.apple.com/tvos/)
  * [visionOS](https://developer.apple.com/visionos/)
  * [watchOS](https://developer.apple.com/watchos/)


###  Tools 
Toggle Menu 
  * [Swift](https://developer.apple.com/swift/)
  * [SwiftUI](https://developer.apple.com/swiftui/)
  * [Swift Playground](https://developer.apple.com/swift-playground/)
  * [TestFlight](https://developer.apple.com/testflight/)
  * [Xcode](https://developer.apple.com/xcode/)
  * [Xcode Cloud](https://developer.apple.com/xcode-cloud/)
  * [SF Symbols](https://developer.apple.com/sf-symbols/)


###  Topics & Technologies 
Toggle Menu 
  * [Accessibility](https://developer.apple.com/accessibility/)
  * [Accessories](https://developer.apple.com/accessories/)
  * [App Extension](https://developer.apple.com/app-extensions/)
  * [App Store](https://developer.apple.com/app-store/)
  * [Audio & Video](https://developer.apple.com/audio/)
  * [Augmented Reality](https://developer.apple.com/augmented-reality/)
  * [Design](https://developer.apple.com/design/)
  * [Distribution](https://developer.apple.com/distribute/)
  * [Education](https://developer.apple.com/education/)
  * [Fonts](https://developer.apple.com/fonts/)
  * [Games](https://developer.apple.com/games/)
  * [Health & Fitness](https://developer.apple.com/health-fitness/)
  * [In-App Purchase](https://developer.apple.com/in-app-purchase/)
  * [Localization](https://developer.apple.com/localization/)
  * [Maps & Location](https://developer.apple.com/maps/)
  * [Machine Learning & AI](https://developer.apple.com/machine-learning/)
  * [Open Source](https://opensource.apple.com/)
  * [Security](https://developer.apple.com/security/)
  * [Safari & Web](https://developer.apple.com/safari/)


###  Resources 
Toggle Menu 
  *   * [Documentation](https://developer.apple.com/documentation/)
  * [Tutorials](https://developer.apple.com/learn/)
  * [Downloads](https://developer.apple.com/download/)
  * [Forums](https://developer.apple.com/forums/)
  * [Videos](https://developer.apple.com/videos/)


###  Support 
Toggle Menu 
  * [Support Articles](https://developer.apple.com/support/articles/)
  * [Contact Us](https://developer.apple.com/contact/)
  * [Bug Reporting](https://developer.apple.com/bug-reporting/)
  * [System Status](https://developer.apple.com/system-status/)


###  Account 
Toggle Menu 
  * [Apple Developer](https://developer.apple.com/account/)
  * [App Store Connect](https://appstoreconnect.apple.com/)
  * [Certificates, IDs, & Profiles](https://developer.apple.com/account/ios/certificate/)
  * [Feedback Assistant](https://feedbackassistant.apple.com/)


###  Programs 
Toggle Menu 
  * [Apple Developer Program](https://developer.apple.com/programs/)
  * [Apple Developer Enterprise Program](https://developer.apple.com/programs/enterprise/)
  * [App Store Small Business Program](https://developer.apple.com/app-store/small-business-program/)
  * [MFi Program](https://mfi.apple.com/)
  * [News Partner Program](https://developer.apple.com/programs/news-partner/)
  * [Video Partner Program](https://developer.apple.com/programs/video-partner/)
  * [Security Bounty Program](https://developer.apple.com/security-bounty/)
  * [Security Research Device Program](https://developer.apple.com/programs/security-research-device/)


###  Events 
Toggle Menu 
  * [Meet with Apple](https://developer.apple.com/events/)
  * [Apple Developer Centers](https://developer.apple.com/events/developer-centers/)
  * [App Store Awards](https://developer.apple.com/app-store/app-store-awards/)
  * [Apple Design Awards](https://developer.apple.com/design/awards/)
  * [Apple Developer Academies](https://developer.apple.com/academies/)
  * [WWDC](https://developer.apple.com/wwdc/)


To submit feedback on documentation, visit [Feedback Assistant](applefeedback://new?form_identifier=developertools.fba&answers%5B%3Aarea%5D=seedADC%3Adevpubs&answers%5B%3Adoc_type_req%5D=Technology%20Documentation&answers%5B%3Adocumentation_link_req%5D=https%3A%2F%2Fdeveloper.apple.com%2Fdocumentation%2Fcoreml%2Funderstanding-a-dice-roll-with-vision-and-object-detection).
Select a color scheme preference
Light
Dark
Auto
Copyright © 2025 [Apple Inc.](https://www.apple.com) All rights reserved. 
[ Terms of Use ](https://www.apple.com/legal/internet-services/terms/site.html)[ Privacy Policy ](https://www.apple.com/legal/privacy/)[ Agreements and Guidelines ](https://developer.apple.com/support/terms/)
