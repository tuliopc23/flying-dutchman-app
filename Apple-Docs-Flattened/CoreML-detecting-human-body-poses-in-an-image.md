Source: https://developer.apple.com/documentation/coreml/detecting-human-body-poses-in-an-image

[ Skip Navigation ](https://developer.apple.com/documentation/coreml/detecting-human-body-poses-in-an-image#app-main)
  * [Global Nav Open Menu](https://developer.apple.com/documentation/coreml/detecting-human-body-poses-in-an-image#ac-gn-menustate)[Global Nav Close Menu](https://developer.apple.com/documentation/coreml/detecting-human-body-poses-in-an-image)
  * [Apple Developer](https://developer.apple.com/)


[ Search Developer Cancel  ](https://developer.apple.com/search/)
  * [Apple Developer](https://developer.apple.com/)
  * [News](https://developer.apple.com/news/)
  * [Discover](https://developer.apple.com/discover/)
  * [Design](https://developer.apple.com/design/)
  * [Develop](https://developer.apple.com/develop/)
  * [Distribute](https://developer.apple.com/distribute/)
  * [Support](https://developer.apple.com/support/)
  * [Account](https://developer.apple.com/account/)
  * [](https://developer.apple.com/search/)


Cancel 
Only search within “Documentation”
### Quick Links
  * [Downloads](https://developer.apple.com/download/)
  * [Documentation](https://developer.apple.com/documentation/)
  * [Sample Code](https://developer.apple.com/documentation/samplecode/)
  * [Videos](https://developer.apple.com/videos/)
  * [Forums](https://developer.apple.com/forums/)

5 Quick Links
[ Documentation ](https://developer.apple.com/documentation)
[ Open Menu ](https://developer.apple.com/documentation/coreml/detecting-human-body-poses-in-an-image)
  * SwiftLanguage:  Swift  Objective-C 
Language: 
    * Swift 
    * [ Objective-C ](https://developer.apple.com/documentation/coreml/detecting-human-body-poses-in-an-image)


[](https://developer.apple.com/documentation/coreml/detecting-human-body-poses-in-an-image)
## [ Core ML  ](https://developer.apple.com/documentation/coreml)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
26 of 54 symbols inside <root> containing 2 symbols[MLGPUComputeDevice](https://developer.apple.com/documentation/coreml/mlgpucomputedevice)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
18 of 54 symbols inside <root> [Downloading and Compiling a Model on the User’s Device](https://developer.apple.com/documentation/coreml/downloading-and-compiling-a-model-on-the-user-s-device)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
18 of 54 symbols inside <root> [Downloading and Compiling a Model on the User’s Device](https://developer.apple.com/documentation/coreml/downloading-and-compiling-a-model-on-the-user-s-device)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
Collection
19 of 54 symbols inside <root> containing 9 symbols[Model Integration Samples](https://developer.apple.com/documentation/coreml/model-integration-samples)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
1 of 9 symbols inside 1345615585 
Tabular data models
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
2 of 9 symbols inside 1345615585 [Integrating a Core ML Model into Your App](https://developer.apple.com/documentation/coreml/integrating-a-core-ml-model-into-your-app)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
3 of 9 symbols inside 1345615585 
Image classification models
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
4 of 9 symbols inside 1345615585 [Using Core ML for semantic image segmentation](https://developer.apple.com/documentation/coreml/using-core-ml-for-semantic-image-segmentation)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
5 of 9 symbols inside 1345615585 [Classifying Images with Vision and Core ML](https://developer.apple.com/documentation/coreml/classifying-images-with-vision-and-core-ml)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
6 of 9 symbols inside 1345615585 [Detecting human body poses in an image](https://developer.apple.com/documentation/coreml/detecting-human-body-poses-in-an-image)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
7 of 9 symbols inside 1345615585 [Understanding a Dice Roll with Vision and Object Detection](https://developer.apple.com/documentation/coreml/understanding-a-dice-roll-with-vision-and-object-detection)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
8 of 9 symbols inside 1345615585 
Text classification models
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
9 of 9 symbols inside 1345615585 [Finding answers to questions in a text document](https://developer.apple.com/documentation/coreml/finding-answers-to-questions-in-a-text-document)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
20 of 54 symbols inside <root>
Model encryption
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
21 of 54 symbols inside <root> [Generating a Model Encryption Key](https://developer.apple.com/documentation/coreml/generating-a-model-encryption-key)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
22 of 54 symbols inside <root> [Encrypting a Model in Your App](https://developer.apple.com/documentation/coreml/encrypting-a-model-in-your-app)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
23 of 54 symbols inside <root>
Compute devices
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
E
24 of 54 symbols inside <root> containing 6 symbols[MLComputeDevice](https://developer.apple.com/documentation/coreml/mlcomputedevice)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
25 of 54 symbols inside <root> [MLCPUComputeDevice](https://developer.apple.com/documentation/coreml/mlcpucomputedevice)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
26 of 54 symbols inside <root> containing 2 symbols[MLGPUComputeDevice](https://developer.apple.com/documentation/coreml/mlgpucomputedevice)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
27 of 54 symbols inside <root> containing 2 symbols[MLNeuralEngineComputeDevice](https://developer.apple.com/documentation/coreml/mlneuralenginecomputedevice)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
rP
28 of 54 symbols inside <root> [MLComputeDeviceProtocol](https://developer.apple.com/documentation/coreml/mlcomputedeviceprotocol)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
29 of 54 symbols inside <root>
Compute plan
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
30 of 54 symbols inside <root> containing 13 symbols[MLComputePlan](https://developer.apple.com/documentation/coreml/mlcomputeplan-1w21n)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
E
31 of 54 symbols inside <root> containing 11 symbols[MLModelStructure](https://developer.apple.com/documentation/coreml/mlmodelstructure-swift.enum)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
S
32 of 54 symbols inside <root> containing 8 symbols[MLComputePolicy](https://developer.apple.com/documentation/coreml/mlcomputepolicy)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
33 of 54 symbols inside <root> [func withMLTensorComputePolicy<R>(MLComputePolicy, () async throws -> R) async rethrows -> R](https://developer.apple.com/documentation/coreml/withmltensorcomputepolicy\(_:_:\)-8stx9)
63 items were found. Tab back to navigate through them. 
/ 
Navigator is ready 
  * [ Core ML ](https://developer.apple.com/documentation/coreml)
  * [ Model Integration Samples ](https://developer.apple.com/documentation/coreml/model-integration-samples)
  * [ Detecting human body poses in an image ](https://developer.apple.com/documentation/coreml/detecting-human-body-poses-in-an-image)
  *     * [ Model Integration Samples ](https://developer.apple.com/documentation/coreml/model-integration-samples)
    * Detecting human body poses in an image 


Sample Code
# Detecting human body poses in an image
Locate people and the stance of their bodies by analyzing an image with a PoseNet model.
[ Download ](https://docs-assets.developer.apple.com/published/3e1c865293a0/DetectingHumanBodyPosesInAnImage.zip)
iOS 13.0+iPadOS 13.0+Xcode 15.2+
## [Overview](https://developer.apple.com/documentation/coreml/detecting-human-body-poses-in-an-image#Overview)
This sample project provides an illustrative example of using a third-party [Core ML](https://developer.apple.com/documentation/CoreML) model, PoseNet, to detect human body poses from frames captured using a camera. PoseNet models detect 17 different body parts or joints: eyes, ears, nose, shoulders, hips, elbows, knees, wrists, and ankles. Collectively these joints form a pose.
![Flow diagram illustrating the sequence of activities for estimating a pose. The flow begins on the left with an iPhone’s camera, proceeding to a PoseNet model, followed by a generic human figure with the 17 labeled joints, and ends with the same human figure but with the joints connected in a wireframe.](https://docs-assets.developer.apple.com/published/1ff62d703f30b89a46aec980da6524d9/PoseNetPipeline%402x.png)
The sample finds the locations of the 17 joints for each person in the image and draws a wireframe pose on top of them.
Note
Starting in iOS 14 and macOS 11, [Vision](https://developer.apple.com/documentation/Vision) adds the ability to detect human body poses. For details, see [Detecting Human Body Poses in Images](https://developer.apple.com/documentation/Vision/detecting-human-body-poses-in-images).
### [Configure the capture session](https://developer.apple.com/documentation/coreml/detecting-human-body-poses-in-an-image#Configure-the-capture-session)
The sample starts by getting an image from the device’s built-in camera using an [`AVCaptureSession`](https://developer.apple.com/documentation/AVFoundation/AVCaptureSession) (see [Setting Up a Capture Session](https://developer.apple.com/documentation/AVFoundation/setting-up-a-capture-session)).
```
if captureSession.isRunning {
    captureSession.stopRunning()
}


captureSession.beginConfiguration()


captureSession.sessionPreset = .vga640x480


try setCaptureSessionInput()


try setCaptureSessionOutput()


captureSession.commitConfiguration()

```

### [Acquire the captured image](https://developer.apple.com/documentation/coreml/detecting-human-body-poses-in-an-image#Acquire-the-captured-image)
```
// Attempt to lock the image buffer to gain access to its memory.
guard CVPixelBufferLockBaseAddress(pixelBuffer, .readOnly) == kCVReturnSuccess
    else {
        return
}


// Create Core Graphics image placeholder.
var image: CGImage?


// Create a Core Graphics bitmap image from the pixel buffer.
VTCreateCGImageFromCVPixelBuffer(pixelBuffer, options: nil, imageOut: &image)


// Release the image buffer.
CVPixelBufferUnlockBaseAddress(pixelBuffer, .readOnly)


DispatchQueue.main.sync {
    delegate.videoCapture(self, didCaptureFrame: image)
}

```

### [Prepare the input for the PoseNet model](https://developer.apple.com/documentation/coreml/detecting-human-body-poses-in-an-image#Prepare-the-input-for-the-PoseNet-model)
```
// Wrap the image in an instance of PoseNetInput to have it resized
// before being passed to the PoseNet model.
let input = PoseNetInput(image: image, size: self.modelInputSize)

```

### [Pass the input to the PoseNet model](https://developer.apple.com/documentation/coreml/detecting-human-body-poses-in-an-image#Pass-the-input-to-the-PoseNet-model)
The sample app then proceeds to pass the input to the PoseNet’s [`prediction`](https://developer.apple.com/documentation/CoreML/MLModel/prediction\(from:\)-9y2aa) function to obtain its outputs, which the app uses to detect poses.
```
guard let prediction = try? self.poseNetMLModel.prediction(from: input) else {
    return
}

```

```
let poseNetOutput = PoseNetOutput(prediction: prediction,
                                  modelInputSize: self.modelInputSize,
                                  modelOutputStride: self.outputStride)


DispatchQueue.main.async {
    self.delegate?.poseNet(self, didPredict: poseNetOutput)
}

```

### [Analyze the PoseNet output to locate joints](https://developer.apple.com/documentation/coreml/detecting-human-body-poses-in-an-image#Analyze-the-PoseNet-output-to-locate-joints)
The sample uses one of two algorithms to locate the joints of either one person or multiple persons. The single-person algorithm, the simplest and fastest, inspects the model’s outputs to locate the most prominent joints in the image and uses these joints to construct a single pose.
```
var pose = Pose()


// For each joint, find its most likely position and associated confidence
// by querying the heatmap array for the cell with the greatest
// confidence and using this to compute its position.
pose.joints.values.forEach { joint in
    configure(joint: joint)
}


// Compute and assign the confidence for the pose.
pose.confidence = pose.joints.values
    .map { $0.confidence }.reduce(0, +) / Double(Joint.numberOfJoints)


// Map the pose joints positions back onto the original image.
pose.joints.values.forEach { joint in
    joint.position = joint.position.applying(modelToInputTransformation)
}


return pose

```

The multiple-person algorithm first identifies a set of candidate root joints as starting points. It uses these root joints to find neighboring joints and repeats the process until it has located all 17 joints of each person. For example, the algorithm may find a left knee with a high confidence, and then search for its adjacent joints, the left ankle and left hip.
```
var detectedPoses = [Pose]()


// Iterate through the joints with the greatest confidence, referred to here as
// candidate roots, using each as a starting point to assemble a pose.
for candidateRoot in candidateRoots {
    // Ignore any candidates that are in the proximity of joints of the
    // same type and have already been assigned to an existing pose.
    let maxDistance = configuration.matchingJointDistance
    guard !detectedPoses.contains(candidateRoot, within: maxDistance) else {
        continue
    }


    var pose = assemblePose(from: candidateRoot)


    // Compute the pose's confidence by dividing the sum of all
    // non-overlapping joints, from existing poses, by the total
    // number of joints.
    pose.confidence = confidence(for: pose, detectedPoses: detectedPoses)


    // Ignore any pose that has a confidence less than the assigned threshold.
    guard pose.confidence >= configuration.poseConfidenceThreshold else {
        continue
    }


    detectedPoses.append(pose)


    // Exit early if enough poses have been detected.
    if detectedPoses.count >= configuration.maxPoseCount {
        break
    }
}


// Map the pose joints positions back onto the original image using
// the pre-computed transformation matrix.
detectedPoses.forEach { pose in
    pose.joints.values.forEach { joint in
        joint.position = joint.position.applying(modelToInputTransformation)
    }
}


return detectedPoses

```

### [Visualize the detected poses](https://developer.apple.com/documentation/coreml/detecting-human-body-poses-in-an-image#Visualize-the-detected-poses)
For each detected pose, the sample app draws a wireframe over the input image, connecting the lines between the joints and then drawing circles for the joints themselves.
![Illustration of a wireframe of connected joints drawn over a generic human figure performing a yoga tree pose.](https://docs-assets.developer.apple.com/published/91060e4ca16a558f9c6bac9f3a2af3e5/PoseNetVisualization%402x.png)
```
let dstImageSize = CGSize(width: frame.width, height: frame.height)
let dstImageFormat = UIGraphicsImageRendererFormat()


dstImageFormat.scale = 1
let renderer = UIGraphicsImageRenderer(size: dstImageSize,
                                       format: dstImageFormat)


let dstImage = renderer.image { rendererContext in
    // Draw the current frame as the background for the new image.
    draw(image: frame, in: rendererContext.cgContext)


    for pose in poses {
        // Draw the segment lines.
        for segment in PoseImageView.jointSegments {
            let jointA = pose[segment.jointA]
            let jointB = pose[segment.jointB]


            guard jointA.isValid, jointB.isValid else {
                continue
            }


            drawLine(from: jointA,
                     to: jointB,
                     in: rendererContext.cgContext)
        }


        // Draw the joints as circles above the segment lines.
        for joint in pose.joints.values.filter({ $0.isValid }) {
            draw(circle: joint, in: rendererContext.cgContext)
        }
    }
}

```

## [See Also](https://developer.apple.com/documentation/coreml/detecting-human-body-poses-in-an-image#see-also)
### [Image classification models](https://developer.apple.com/documentation/coreml/detecting-human-body-poses-in-an-image#Image-classification-models)
[Using Core ML for semantic image segmentation](https://developer.apple.com/documentation/coreml/using-core-ml-for-semantic-image-segmentation)
Identify multiple objects in an image by using the DEtection TRansformer image-segmentation model.
[Classifying Images with Vision and Core ML](https://developer.apple.com/documentation/coreml/classifying-images-with-vision-and-core-ml)
Crop and scale photos using the Vision framework and classify them with a Core ML model.
[Understanding a Dice Roll with Vision and Object Detection](https://developer.apple.com/documentation/coreml/understanding-a-dice-roll-with-vision-and-object-detection)
Detect dice position and values shown in a camera frame, and determine the end of a roll by leveraging a dice detection model.
Current page is Detecting human body poses in an image 
[Apple](https://www.apple.com)
  1. [Developer](https://developer.apple.com/)
  2. [ Documentation ](https://developer.apple.com/documentation/)


###  Platforms 
Toggle Menu 
  * [iOS](https://developer.apple.com/ios/)
  * [iPadOS](https://developer.apple.com/ipados/)
  * [macOS](https://developer.apple.com/macos/)
  * [tvOS](https://developer.apple.com/tvos/)
  * [visionOS](https://developer.apple.com/visionos/)
  * [watchOS](https://developer.apple.com/watchos/)


###  Tools 
Toggle Menu 
  * [Swift](https://developer.apple.com/swift/)
  * [SwiftUI](https://developer.apple.com/swiftui/)
  * [Swift Playground](https://developer.apple.com/swift-playground/)
  * [TestFlight](https://developer.apple.com/testflight/)
  * [Xcode](https://developer.apple.com/xcode/)
  * [Xcode Cloud](https://developer.apple.com/xcode-cloud/)
  * [SF Symbols](https://developer.apple.com/sf-symbols/)


###  Topics & Technologies 
Toggle Menu 
  * [Accessibility](https://developer.apple.com/accessibility/)
  * [Accessories](https://developer.apple.com/accessories/)
  * [App Extension](https://developer.apple.com/app-extensions/)
  * [App Store](https://developer.apple.com/app-store/)
  * [Audio & Video](https://developer.apple.com/audio/)
  * [Augmented Reality](https://developer.apple.com/augmented-reality/)
  * [Design](https://developer.apple.com/design/)
  * [Distribution](https://developer.apple.com/distribute/)
  * [Education](https://developer.apple.com/education/)
  * [Fonts](https://developer.apple.com/fonts/)
  * [Games](https://developer.apple.com/games/)
  * [Health & Fitness](https://developer.apple.com/health-fitness/)
  * [In-App Purchase](https://developer.apple.com/in-app-purchase/)
  * [Localization](https://developer.apple.com/localization/)
  * [Maps & Location](https://developer.apple.com/maps/)
  * [Machine Learning & AI](https://developer.apple.com/machine-learning/)
  * [Open Source](https://opensource.apple.com/)
  * [Security](https://developer.apple.com/security/)
  * [Safari & Web](https://developer.apple.com/safari/)


###  Resources 
Toggle Menu 
  *   * [Documentation](https://developer.apple.com/documentation/)
  * [Tutorials](https://developer.apple.com/learn/)
  * [Downloads](https://developer.apple.com/download/)
  * [Forums](https://developer.apple.com/forums/)
  * [Videos](https://developer.apple.com/videos/)


###  Support 
Toggle Menu 
  * [Support Articles](https://developer.apple.com/support/articles/)
  * [Contact Us](https://developer.apple.com/contact/)
  * [Bug Reporting](https://developer.apple.com/bug-reporting/)
  * [System Status](https://developer.apple.com/system-status/)


###  Account 
Toggle Menu 
  * [Apple Developer](https://developer.apple.com/account/)
  * [App Store Connect](https://appstoreconnect.apple.com/)
  * [Certificates, IDs, & Profiles](https://developer.apple.com/account/ios/certificate/)
  * [Feedback Assistant](https://feedbackassistant.apple.com/)


###  Programs 
Toggle Menu 
  * [Apple Developer Program](https://developer.apple.com/programs/)
  * [Apple Developer Enterprise Program](https://developer.apple.com/programs/enterprise/)
  * [App Store Small Business Program](https://developer.apple.com/app-store/small-business-program/)
  * [MFi Program](https://mfi.apple.com/)
  * [News Partner Program](https://developer.apple.com/programs/news-partner/)
  * [Video Partner Program](https://developer.apple.com/programs/video-partner/)
  * [Security Bounty Program](https://developer.apple.com/security-bounty/)
  * [Security Research Device Program](https://developer.apple.com/programs/security-research-device/)


###  Events 
Toggle Menu 
  * [Meet with Apple](https://developer.apple.com/events/)
  * [Apple Developer Centers](https://developer.apple.com/events/developer-centers/)
  * [App Store Awards](https://developer.apple.com/app-store/app-store-awards/)
  * [Apple Design Awards](https://developer.apple.com/design/awards/)
  * [Apple Developer Academies](https://developer.apple.com/academies/)
  * [WWDC](https://developer.apple.com/wwdc/)


To submit feedback on documentation, visit [Feedback Assistant](applefeedback://new?form_identifier=developertools.fba&answers%5B%3Aarea%5D=seedADC%3Adevpubs&answers%5B%3Adoc_type_req%5D=Technology%20Documentation&answers%5B%3Adocumentation_link_req%5D=https%3A%2F%2Fdeveloper.apple.com%2Fdocumentation%2Fcoreml%2Fdetecting-human-body-poses-in-an-image).
Select a color scheme preference
Light
Dark
Auto
Copyright © 2025 [Apple Inc.](https://www.apple.com) All rights reserved. 
[ Terms of Use ](https://www.apple.com/legal/internet-services/terms/site.html)[ Privacy Policy ](https://www.apple.com/legal/privacy/)[ Agreements and Guidelines ](https://developer.apple.com/support/terms/)
