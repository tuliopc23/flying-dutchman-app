Source: https://developer.apple.com/documentation/avfoundation/capturing-depth-using-the-lidar-camera

[ Skip Navigation ](https://developer.apple.com/documentation/avfoundation/capturing-depth-using-the-lidar-camera#app-main)
  * [Global Nav Open Menu](https://developer.apple.com/documentation/avfoundation/capturing-depth-using-the-lidar-camera#ac-gn-menustate)[Global Nav Close Menu](https://developer.apple.com/documentation/avfoundation/capturing-depth-using-the-lidar-camera)
  * [Apple Developer](https://developer.apple.com/)


[ Search Developer Cancel  ](https://developer.apple.com/search/)
  * [Apple Developer](https://developer.apple.com/)
  * [News](https://developer.apple.com/news/)
  * [Discover](https://developer.apple.com/discover/)
  * [Design](https://developer.apple.com/design/)
  * [Develop](https://developer.apple.com/develop/)
  * [Distribute](https://developer.apple.com/distribute/)
  * [Support](https://developer.apple.com/support/)
  * [Account](https://developer.apple.com/account/)
  * [](https://developer.apple.com/search/)


Cancel 
Only search within “Documentation”
### Quick Links
  * [Downloads](https://developer.apple.com/download/)
  * [Documentation](https://developer.apple.com/documentation/)
  * [Sample Code](https://developer.apple.com/documentation/samplecode/)
  * [Videos](https://developer.apple.com/videos/)
  * [Forums](https://developer.apple.com/forums/)

5 Quick Links
[ Documentation ](https://developer.apple.com/documentation)
[ Open Menu ](https://developer.apple.com/documentation/avfoundation/capturing-depth-using-the-lidar-camera)
  * SwiftLanguage: Swift


[](https://developer.apple.com/documentation/avfoundation/capturing-depth-using-the-lidar-camera)
## [ AVFoundation  ](https://developer.apple.com/documentation/avfoundation)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
Collection
15 of 22 symbols inside 2121978169 containing 15 symbols[Metadata types](https://developer.apple.com/documentation/avfoundation/metadata-types)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
Collection
15 of 31 symbols inside <root> containing 54 symbols[Capture setup](https://developer.apple.com/documentation/avfoundation/capture-setup)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
Collection
16 of 31 symbols inside <root> containing 19 symbols[Photo capture](https://developer.apple.com/documentation/avfoundation/photo-capture)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
Collection
17 of 31 symbols inside <root> containing 14 symbols[Audio and video capture](https://developer.apple.com/documentation/avfoundation/audio-and-video-capture)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
Collection
18 of 31 symbols inside <root> containing 22 symbols[Additional data capture](https://developer.apple.com/documentation/avfoundation/additional-data-capture)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
1 of 22 symbols inside 2121978169 
Depth data capture
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
2 of 22 symbols inside 2121978169 [Capturing photos with depth](https://developer.apple.com/documentation/avfoundation/capturing-photos-with-depth)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
3 of 22 symbols inside 2121978169 [Creating auxiliary depth data manually](https://developer.apple.com/documentation/avfoundation/creating-auxiliary-depth-data-manually)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
4 of 22 symbols inside 2121978169 [Capturing depth using the LiDAR camera](https://developer.apple.com/documentation/avfoundation/capturing-depth-using-the-lidar-camera)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
5 of 22 symbols inside 2121978169 [AVCamFilter: Applying filters to a capture stream](https://developer.apple.com/documentation/avfoundation/avcamfilter-applying-filters-to-a-capture-stream)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
6 of 22 symbols inside 2121978169 [Streaming depth data from the TrueDepth camera](https://developer.apple.com/documentation/avfoundation/streaming-depth-data-from-the-truedepth-camera)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
7 of 22 symbols inside 2121978169 [Enhancing live video by leveraging TrueDepth camera data](https://developer.apple.com/documentation/avfoundation/enhancing-live-video-by-leveraging-truedepth-camera-data)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
8 of 22 symbols inside 2121978169 containing 10 symbols[AVCaptureDepthDataOutput](https://developer.apple.com/documentation/avfoundation/avcapturedepthdataoutput)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
9 of 22 symbols inside 2121978169 containing 19 symbols[AVDepthData](https://developer.apple.com/documentation/avfoundation/avdepthdata)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
10 of 22 symbols inside 2121978169 containing 9 symbols[AVCameraCalibrationData](https://developer.apple.com/documentation/avfoundation/avcameracalibrationdata)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
11 of 22 symbols inside 2121978169 
Metadata capture
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
12 of 22 symbols inside 2121978169 containing 4 symbols[AVCaptureMetadataInput](https://developer.apple.com/documentation/avfoundation/avcapturemetadatainput)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
13 of 22 symbols inside 2121978169 containing 12 symbols[AVCaptureMetadataOutput](https://developer.apple.com/documentation/avfoundation/avcapturemetadataoutput)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
14 of 22 symbols inside 2121978169 containing 10 symbols[AVMetadataObject](https://developer.apple.com/documentation/avfoundation/avmetadataobject)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
Collection
15 of 22 symbols inside 2121978169 containing 15 symbols[Metadata types](https://developer.apple.com/documentation/avfoundation/metadata-types)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
16 of 22 symbols inside 2121978169 
Synchronized capture
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
17 of 22 symbols inside 2121978169 containing 8 symbols[AVCaptureDataOutputSynchronizer](https://developer.apple.com/documentation/avfoundation/avcapturedataoutputsynchronizer)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
18 of 22 symbols inside 2121978169 containing 4 symbols[AVCaptureSynchronizedDataCollection](https://developer.apple.com/documentation/avfoundation/avcapturesynchronizeddatacollection)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
19 of 22 symbols inside 2121978169 containing 5 symbols[AVCaptureSynchronizedSampleBufferData](https://developer.apple.com/documentation/avfoundation/avcapturesynchronizedsamplebufferdata)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
20 of 22 symbols inside 2121978169 containing 2 symbols[AVCaptureSynchronizedMetadataObjectData](https://developer.apple.com/documentation/avfoundation/avcapturesynchronizedmetadataobjectdata)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
21 of 22 symbols inside 2121978169 containing 5 symbols[AVCaptureSynchronizedDepthData](https://developer.apple.com/documentation/avfoundation/avcapturesynchronizeddepthdata)
53 items were found. Tab back to navigate through them. 
/ 
Navigator is ready 
  * [ AVFoundation ](https://developer.apple.com/documentation/avfoundation)
  * [ Additional data capture ](https://developer.apple.com/documentation/avfoundation/additional-data-capture)
  * [ Capturing depth using the LiDAR camera ](https://developer.apple.com/documentation/avfoundation/capturing-depth-using-the-lidar-camera)
  *     * [ Additional data capture ](https://developer.apple.com/documentation/avfoundation/additional-data-capture)
    * Capturing depth using the LiDAR camera 


Sample Code
# Capturing depth using the LiDAR camera
Access the LiDAR camera on supporting devices to capture precise depth data.
[ Download ](https://docs-assets.developer.apple.com/published/fc8364208145/CapturingDepthUsingTheLiDARCamera.zip)
iOS 15.6+iPadOS 15.6+Xcode 16.0+
## [Overview](https://developer.apple.com/documentation/avfoundation/capturing-depth-using-the-lidar-camera#Overview)
AVFoundation introduced depth data capture for photos and video in iOS 11. The data it provides is suitable for many apps, but may not meet the needs of those that require greater precision depth. Starting in iOS 15.4, you can access the LiDAR camera on supported hardware, which offers high-precision depth data suitable for use cases like room scanning and measurement.
This sample code project shows how to capture and render depth data from the LiDAR camera. It starts in streaming mode, which demonstrates how to capture synchronized video and depth data. When you tap the Camera button in the upper-left corner of the screen, the app switches to photo mode, which illustrates how to capture photos with depth data. In both modes, the app provides several Metal-based visualizations of the depth and image data.
### [Configure the sample code project](https://developer.apple.com/documentation/avfoundation/capturing-depth-using-the-lidar-camera#Configure-the-sample-code-project)
Run this sample code on a device that provides a LiDAR camera, such as:
  * iPhone 12 Pro or later
  * iPad Pro 11-inch (3rd generation) or later
  * iPad Pro 12.9-inch (5th generation) or later


### [Configure the LiDAR camera](https://developer.apple.com/documentation/avfoundation/capturing-depth-using-the-lidar-camera#Configure-the-LiDAR-camera)
The sample app’s `CameraController` class provides the code that configures and manages the capture session, and handles the delivery of new video and depth data. It begins its configuration by retrieving the LiDAR camera. It calls the capture device’s [`default(_:for:position:)`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/default\(_:for:position:\)) class method, passing it the new [`builtInLiDARDepthCamera`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/devicetype-swift.struct/builtinlidardepthcamera) device type available in iOS 15.4 and later.
```
// Look up the LiDAR camera.
guard let device = AVCaptureDevice.default(.builtInLiDARDepthCamera, for: .video, position: .back) else {
    throw ConfigurationError.lidarDeviceUnavailable
}

```

After retrieving the device, the app configures it with a specific video and depth format. It asks the device for its supported formats and finds the best nonbinned, full-range YUV color format that matches the sample app’s preferred width and supports depth capture. Finally, it sets the active formats on the device as in the following code example:
```
// Find a match that outputs video data in the format the app's custom Metal views require.
guard let format = (device.formats.last { format in
    format.formatDescription.dimensions.width == preferredWidthResolution &&
    format.formatDescription.mediaSubType.rawValue == kCVPixelFormatType_420YpCbCr8BiPlanarFullRange &&
    !format.isVideoBinned &&
    !format.supportedDepthDataFormats.isEmpty
}) else {
    throw ConfigurationError.requiredFormatUnavailable
}


// Find a match that outputs depth data in the format the app's custom Metal views require.
guard let depthFormat = (format.supportedDepthDataFormats.last { depthFormat in
    depthFormat.formatDescription.mediaSubType.rawValue == kCVPixelFormatType_DepthFloat16
}) else {
    throw ConfigurationError.requiredFormatUnavailable
}


// Begin the device configuration.
try device.lockForConfiguration()


// Configure the device and depth formats.
device.activeFormat = format
device.activeDepthDataFormat = depthFormat


// Finish the device configuration.
device.unlockForConfiguration()

```

### [Configure the capture outputs](https://developer.apple.com/documentation/avfoundation/capturing-depth-using-the-lidar-camera#Configure-the-capture-outputs)
The app operates in streaming or photo mode. To enable streaming output, it creates an instance of [`AVCaptureVideoDataOutput`](https://developer.apple.com/documentation/avfoundation/avcapturevideodataoutput) and [`AVCaptureDepthDataOutput`](https://developer.apple.com/documentation/avfoundation/avcapturedepthdataoutput) to capture video sample buffers and depth data, respectively. It configures them as follows:
```
// Create an object to output video sample buffers.
videoDataOutput = AVCaptureVideoDataOutput()
captureSession.addOutput(videoDataOutput)


// Create an object to output depth data.
depthDataOutput = AVCaptureDepthDataOutput()
depthDataOutput.isFilteringEnabled = isFilteringEnabled
captureSession.addOutput(depthDataOutput)


// Create an object to synchronize the delivery of depth and video data.
outputVideoSync = AVCaptureDataOutputSynchronizer(dataOutputs: [depthDataOutput, videoDataOutput])
outputVideoSync.setDelegate(self, queue: videoQueue)

```

Because the video and depth data stream from separate output objects, the sample uses an [`AVCaptureDataOutputSynchronizer`](https://developer.apple.com/documentation/avfoundation/avcapturedataoutputsynchronizer) to synchronize the delivery from both outputs to a single callback. The `CameraController` class adopts the synchronizer’s [`AVCaptureDataOutputSynchronizerDelegate`](https://developer.apple.com/documentation/avfoundation/avcapturedataoutputsynchronizerdelegate) protocol and responds to the delivery of new video and depth data.
To handle photo capture, the app also creates an instance of [`AVCapturePhotoOutput`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput). It optimizes the output for high-quality capture and adds the output to the capture session.
```
// Create an object to output photos.
photoOutput = AVCapturePhotoOutput()
photoOutput.maxPhotoQualityPrioritization = .quality
captureSession.addOutput(photoOutput)


// Enable delivery of depth data after adding the output to the capture session.
photoOutput.isDepthDataDeliveryEnabled = true

```

After it adds the output to the session, it enables the delivery of depth data, which configures the capture pipeline appropriately. It can only enable depth delivery after adding the output to the capture session because the output needs to determine whether the pipeline configuration can deliver it.
### [Capture synchronized video and depth](https://developer.apple.com/documentation/avfoundation/capturing-depth-using-the-lidar-camera#Capture-synchronized-video-and-depth)
After configuring the capture session’s inputs and outputs as required, the app is ready to start capturing data. The app starts in streaming mode, which uses the video data and depth data outputs and an `AVCaptureDataOutputSynchronizer` to synchronize the delivery of their data. The app adopts the synchronizer’s delegate protocol and implements its [`dataOutputSynchronizer(_:didOutput:)`](https://developer.apple.com/documentation/avfoundation/avcapturedataoutputsynchronizerdelegate/dataoutputsynchronizer\(_:didoutput:\)) method to handle the delivery, as the following example shows:
```
func dataOutputSynchronizer(_ synchronizer: AVCaptureDataOutputSynchronizer,
                            didOutput synchronizedDataCollection: AVCaptureSynchronizedDataCollection) {
    // Retrieve the synchronized depth and sample buffer container objects.
    guard let syncedDepthData = synchronizedDataCollection.synchronizedData(for: depthDataOutput) as? AVCaptureSynchronizedDepthData,
          let syncedVideoData = synchronizedDataCollection.synchronizedData(for: videoDataOutput) as? AVCaptureSynchronizedSampleBufferData else { return }
    
    guard let pixelBuffer = syncedVideoData.sampleBuffer.imageBuffer,
          let cameraCalibrationData = syncedDepthData.depthData.cameraCalibrationData else { return }
    
    // Package the captured data.
    let data = CameraCapturedData(depth: syncedDepthData.depthData.depthDataMap.texture(withFormat: .r16Float, planeIndex: 0, addToCache: textureCache),
                                  colorY: pixelBuffer.texture(withFormat: .r8Unorm, planeIndex: 0, addToCache: textureCache),
                                  colorCbCr: pixelBuffer.texture(withFormat: .rg8Unorm, planeIndex: 1, addToCache: textureCache),
                                  cameraIntrinsics: cameraCalibrationData.intrinsicMatrix,
                                  cameraReferenceDimensions: cameraCalibrationData.intrinsicMatrixReferenceDimensions)
    
    delegate?.onNewData(capturedData: data)
}

```

The app retrieves the container objects that store the synchronized data from the [`AVCaptureSynchronizedDataCollection`](https://developer.apple.com/documentation/avfoundation/avcapturesynchronizeddatacollection). It then unwraps the underlying video pixel buffer and depth data, and packages them for the app’s Metal views to display.
### [Capture photos and depth](https://developer.apple.com/documentation/avfoundation/capturing-depth-using-the-lidar-camera#Capture-photos-and-depth)
When you tap the app’s Camera button in the upper-left corner of the user interface, the app switches to photo mode. When this occurs, the app calls its `capturePhoto()` method, which creates a photo settings object, requests depth delivery on it, and initiates a photo capture.
```
func capturePhoto() {
    var photoSettings: AVCapturePhotoSettings
    if  photoOutput.availablePhotoPixelFormatTypes.contains(kCVPixelFormatType_420YpCbCr8BiPlanarFullRange) {
        photoSettings = AVCapturePhotoSettings(format: [
            kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_420YpCbCr8BiPlanarFullRange
        ])
    } else {
        photoSettings = AVCapturePhotoSettings()
    }
    
    // Capture depth data with this photo capture.
    photoSettings.isDepthDataDeliveryEnabled = true
    photoOutput.capturePhoto(with: photoSettings, delegate: self)
}

```

When the framework finishes the photo capture, it calls the photo output’s delegate method and passes it the [`AVCapturePhoto`](https://developer.apple.com/documentation/avfoundation/avcapturephoto) object that contains the image and depth data. The sample retrieves the data from the photo, stops the stream until the user returns to streaming mode, and, similarly to the video case, packages the captured data for delivery to the app’s user interface layer.
```
func photoOutput(_ output: AVCapturePhotoOutput, didFinishProcessingPhoto photo: AVCapturePhoto, error: Error?) {
    
    // Retrieve the image and depth data.
    guard let pixelBuffer = photo.pixelBuffer,
          let depthData = photo.depthData,
          let cameraCalibrationData = depthData.cameraCalibrationData else { return }
    
    // Stop the stream until the user returns to streaming mode.
    stopStream()
    
    // Convert the depth data to the expected format.
    let convertedDepth = depthData.converting(toDepthDataType: kCVPixelFormatType_DepthFloat16)
    
    // Package the captured data.
    let data = CameraCapturedData(depth: convertedDepth.depthDataMap.texture(withFormat: .r16Float, planeIndex: 0, addToCache: textureCache),
                                  colorY: pixelBuffer.texture(withFormat: .r8Unorm, planeIndex: 0, addToCache: textureCache),
                                  colorCbCr: pixelBuffer.texture(withFormat: .rg8Unorm, planeIndex: 1, addToCache: textureCache),
                                  cameraIntrinsics: cameraCalibrationData.intrinsicMatrix,
                                  cameraReferenceDimensions: cameraCalibrationData.intrinsicMatrixReferenceDimensions)
    
    delegate?.onNewPhotoData(capturedData: data)
}

```

## [See Also](https://developer.apple.com/documentation/avfoundation/capturing-depth-using-the-lidar-camera#see-also)
### [Depth data capture](https://developer.apple.com/documentation/avfoundation/capturing-depth-using-the-lidar-camera#Depth-data-capture)
[Capturing photos with depth](https://developer.apple.com/documentation/avfoundation/capturing-photos-with-depth)
Get a depth map with a photo to create effects like the system camera’s Portrait mode (on compatible devices).
[Creating auxiliary depth data manually](https://developer.apple.com/documentation/avfoundation/creating-auxiliary-depth-data-manually)
Generate a depth image and attach it to your own image.
[AVCamFilter: Applying filters to a capture stream](https://developer.apple.com/documentation/avfoundation/avcamfilter-applying-filters-to-a-capture-stream)
Render a capture stream with rose-colored filtering and depth effects.
[Streaming depth data from the TrueDepth camera](https://developer.apple.com/documentation/avfoundation/streaming-depth-data-from-the-truedepth-camera)
Visualize depth data in 2D and 3D from the TrueDepth camera.
[Enhancing live video by leveraging TrueDepth camera data](https://developer.apple.com/documentation/avfoundation/enhancing-live-video-by-leveraging-truedepth-camera-data)
Apply your own background to a live capture feed streamed from the front-facing TrueDepth camera.
[`class AVCaptureDepthDataOutput`](https://developer.apple.com/documentation/avfoundation/avcapturedepthdataoutput)
A capture output that records scene depth information on compatible camera devices.
[`class AVDepthData`](https://developer.apple.com/documentation/avfoundation/avdepthdata)
A container for per-pixel distance or disparity information captured by compatible camera devices.
[`class AVCameraCalibrationData`](https://developer.apple.com/documentation/avfoundation/avcameracalibrationdata)
Information about the camera characteristics used to capture images and depth data.
Current page is Capturing depth using the LiDAR camera 
[Apple](https://www.apple.com)
  1. [Developer](https://developer.apple.com/)
  2. [ Documentation ](https://developer.apple.com/documentation/)


###  Platforms 
Toggle Menu 
  * [iOS](https://developer.apple.com/ios/)
  * [iPadOS](https://developer.apple.com/ipados/)
  * [macOS](https://developer.apple.com/macos/)
  * [tvOS](https://developer.apple.com/tvos/)
  * [visionOS](https://developer.apple.com/visionos/)
  * [watchOS](https://developer.apple.com/watchos/)


###  Tools 
Toggle Menu 
  * [Swift](https://developer.apple.com/swift/)
  * [SwiftUI](https://developer.apple.com/swiftui/)
  * [Swift Playground](https://developer.apple.com/swift-playground/)
  * [TestFlight](https://developer.apple.com/testflight/)
  * [Xcode](https://developer.apple.com/xcode/)
  * [Xcode Cloud](https://developer.apple.com/xcode-cloud/)
  * [SF Symbols](https://developer.apple.com/sf-symbols/)


###  Topics & Technologies 
Toggle Menu 
  * [Accessibility](https://developer.apple.com/accessibility/)
  * [Accessories](https://developer.apple.com/accessories/)
  * [App Extension](https://developer.apple.com/app-extensions/)
  * [App Store](https://developer.apple.com/app-store/)
  * [Audio & Video](https://developer.apple.com/audio/)
  * [Augmented Reality](https://developer.apple.com/augmented-reality/)
  * [Design](https://developer.apple.com/design/)
  * [Distribution](https://developer.apple.com/distribute/)
  * [Education](https://developer.apple.com/education/)
  * [Fonts](https://developer.apple.com/fonts/)
  * [Games](https://developer.apple.com/games/)
  * [Health & Fitness](https://developer.apple.com/health-fitness/)
  * [In-App Purchase](https://developer.apple.com/in-app-purchase/)
  * [Localization](https://developer.apple.com/localization/)
  * [Maps & Location](https://developer.apple.com/maps/)
  * [Machine Learning & AI](https://developer.apple.com/machine-learning/)
  * [Open Source](https://opensource.apple.com/)
  * [Security](https://developer.apple.com/security/)
  * [Safari & Web](https://developer.apple.com/safari/)


###  Resources 
Toggle Menu 
  *   * [Documentation](https://developer.apple.com/documentation/)
  * [Tutorials](https://developer.apple.com/learn/)
  * [Downloads](https://developer.apple.com/download/)
  * [Forums](https://developer.apple.com/forums/)
  * [Videos](https://developer.apple.com/videos/)


###  Support 
Toggle Menu 
  * [Support Articles](https://developer.apple.com/support/articles/)
  * [Contact Us](https://developer.apple.com/contact/)
  * [Bug Reporting](https://developer.apple.com/bug-reporting/)
  * [System Status](https://developer.apple.com/system-status/)


###  Account 
Toggle Menu 
  * [Apple Developer](https://developer.apple.com/account/)
  * [App Store Connect](https://appstoreconnect.apple.com/)
  * [Certificates, IDs, & Profiles](https://developer.apple.com/account/ios/certificate/)
  * [Feedback Assistant](https://feedbackassistant.apple.com/)


###  Programs 
Toggle Menu 
  * [Apple Developer Program](https://developer.apple.com/programs/)
  * [Apple Developer Enterprise Program](https://developer.apple.com/programs/enterprise/)
  * [App Store Small Business Program](https://developer.apple.com/app-store/small-business-program/)
  * [MFi Program](https://mfi.apple.com/)
  * [News Partner Program](https://developer.apple.com/programs/news-partner/)
  * [Video Partner Program](https://developer.apple.com/programs/video-partner/)
  * [Security Bounty Program](https://developer.apple.com/security-bounty/)
  * [Security Research Device Program](https://developer.apple.com/programs/security-research-device/)


###  Events 
Toggle Menu 
  * [Meet with Apple](https://developer.apple.com/events/)
  * [Apple Developer Centers](https://developer.apple.com/events/developer-centers/)
  * [App Store Awards](https://developer.apple.com/app-store/app-store-awards/)
  * [Apple Design Awards](https://developer.apple.com/design/awards/)
  * [Apple Developer Academies](https://developer.apple.com/academies/)
  * [WWDC](https://developer.apple.com/wwdc/)


To submit feedback on documentation, visit [Feedback Assistant](applefeedback://new?form_identifier=developertools.fba&answers%5B%3Aarea%5D=seedADC%3Adevpubs&answers%5B%3Adoc_type_req%5D=Technology%20Documentation&answers%5B%3Adocumentation_link_req%5D=https%3A%2F%2Fdeveloper.apple.com%2Fdocumentation%2Favfoundation%2Fcapturing-depth-using-the-lidar-camera).
Select a color scheme preference
Light
Dark
Auto
Copyright © 2025 [Apple Inc.](https://www.apple.com) All rights reserved. 
[ Terms of Use ](https://www.apple.com/legal/internet-services/terms/site.html)[ Privacy Policy ](https://www.apple.com/legal/privacy/)[ Agreements and Guidelines ](https://developer.apple.com/support/terms/)
