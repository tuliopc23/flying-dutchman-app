Source: https://developer.apple.com/documentation/avfoundation/streaming-depth-data-from-the-truedepth-camera

[ Skip Navigation ](https://developer.apple.com/documentation/avfoundation/streaming-depth-data-from-the-truedepth-camera#app-main)
  * [Global Nav Open Menu](https://developer.apple.com/documentation/avfoundation/streaming-depth-data-from-the-truedepth-camera#ac-gn-menustate)[Global Nav Close Menu](https://developer.apple.com/documentation/avfoundation/streaming-depth-data-from-the-truedepth-camera)
  * [Apple Developer](https://developer.apple.com/)


[ Search Developer Cancel  ](https://developer.apple.com/search/)
  * [Apple Developer](https://developer.apple.com/)
  * [News](https://developer.apple.com/news/)
  * [Discover](https://developer.apple.com/discover/)
  * [Design](https://developer.apple.com/design/)
  * [Develop](https://developer.apple.com/develop/)
  * [Distribute](https://developer.apple.com/distribute/)
  * [Support](https://developer.apple.com/support/)
  * [Account](https://developer.apple.com/account/)
  * [](https://developer.apple.com/search/)


Cancel 
Only search within “Documentation”
### Quick Links
  * [Downloads](https://developer.apple.com/download/)
  * [Documentation](https://developer.apple.com/documentation/)
  * [Sample Code](https://developer.apple.com/documentation/samplecode/)
  * [Videos](https://developer.apple.com/videos/)
  * [Forums](https://developer.apple.com/forums/)

5 Quick Links
[ Documentation ](https://developer.apple.com/documentation)
[ Open Menu ](https://developer.apple.com/documentation/avfoundation/streaming-depth-data-from-the-truedepth-camera)
  * SwiftLanguage:  Swift  Objective-C 
Language: 
    * Swift 
    * [ Objective-C ](https://developer.apple.com/documentation/avfoundation/streaming-depth-data-from-the-truedepth-camera)


[](https://developer.apple.com/documentation/avfoundation/streaming-depth-data-from-the-truedepth-camera)
## [ AVFoundation  ](https://developer.apple.com/documentation/avfoundation)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
16 of 22 symbols inside 2121978169 
Synchronized capture
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
Collection
18 of 31 symbols inside <root> containing 22 symbols[Additional data capture](https://developer.apple.com/documentation/avfoundation/additional-data-capture)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
Collection
17 of 31 symbols inside <root> containing 14 symbols[Audio and video capture](https://developer.apple.com/documentation/avfoundation/audio-and-video-capture)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
Collection
18 of 31 symbols inside <root> containing 22 symbols[Additional data capture](https://developer.apple.com/documentation/avfoundation/additional-data-capture)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
1 of 22 symbols inside 2121978169 
Depth data capture
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
2 of 22 symbols inside 2121978169 [Capturing photos with depth](https://developer.apple.com/documentation/avfoundation/capturing-photos-with-depth)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
3 of 22 symbols inside 2121978169 [Creating auxiliary depth data manually](https://developer.apple.com/documentation/avfoundation/creating-auxiliary-depth-data-manually)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
4 of 22 symbols inside 2121978169 [Capturing depth using the LiDAR camera](https://developer.apple.com/documentation/avfoundation/capturing-depth-using-the-lidar-camera)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
5 of 22 symbols inside 2121978169 [AVCamFilter: Applying filters to a capture stream](https://developer.apple.com/documentation/avfoundation/avcamfilter-applying-filters-to-a-capture-stream)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
6 of 22 symbols inside 2121978169 [Streaming depth data from the TrueDepth camera](https://developer.apple.com/documentation/avfoundation/streaming-depth-data-from-the-truedepth-camera)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
7 of 22 symbols inside 2121978169 [Enhancing live video by leveraging TrueDepth camera data](https://developer.apple.com/documentation/avfoundation/enhancing-live-video-by-leveraging-truedepth-camera-data)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
8 of 22 symbols inside 2121978169 containing 10 symbols[AVCaptureDepthDataOutput](https://developer.apple.com/documentation/avfoundation/avcapturedepthdataoutput)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
9 of 22 symbols inside 2121978169 containing 19 symbols[AVDepthData](https://developer.apple.com/documentation/avfoundation/avdepthdata)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
10 of 22 symbols inside 2121978169 containing 9 symbols[AVCameraCalibrationData](https://developer.apple.com/documentation/avfoundation/avcameracalibrationdata)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
11 of 22 symbols inside 2121978169 
Metadata capture
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
12 of 22 symbols inside 2121978169 containing 4 symbols[AVCaptureMetadataInput](https://developer.apple.com/documentation/avfoundation/avcapturemetadatainput)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
13 of 22 symbols inside 2121978169 containing 12 symbols[AVCaptureMetadataOutput](https://developer.apple.com/documentation/avfoundation/avcapturemetadataoutput)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
14 of 22 symbols inside 2121978169 containing 10 symbols[AVMetadataObject](https://developer.apple.com/documentation/avfoundation/avmetadataobject)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
Collection
15 of 22 symbols inside 2121978169 containing 15 symbols[Metadata types](https://developer.apple.com/documentation/avfoundation/metadata-types)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
16 of 22 symbols inside 2121978169 
Synchronized capture
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
17 of 22 symbols inside 2121978169 containing 8 symbols[AVCaptureDataOutputSynchronizer](https://developer.apple.com/documentation/avfoundation/avcapturedataoutputsynchronizer)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
18 of 22 symbols inside 2121978169 containing 4 symbols[AVCaptureSynchronizedDataCollection](https://developer.apple.com/documentation/avfoundation/avcapturesynchronizeddatacollection)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
19 of 22 symbols inside 2121978169 containing 5 symbols[AVCaptureSynchronizedSampleBufferData](https://developer.apple.com/documentation/avfoundation/avcapturesynchronizedsamplebufferdata)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
20 of 22 symbols inside 2121978169 containing 2 symbols[AVCaptureSynchronizedMetadataObjectData](https://developer.apple.com/documentation/avfoundation/avcapturesynchronizedmetadataobjectdata)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
21 of 22 symbols inside 2121978169 containing 5 symbols[AVCaptureSynchronizedDepthData](https://developer.apple.com/documentation/avfoundation/avcapturesynchronizeddepthdata)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
22 of 22 symbols inside 2121978169 containing 2 symbols[AVCaptureSynchronizedData](https://developer.apple.com/documentation/avfoundation/avcapturesynchronizeddata)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
19 of 31 symbols inside <root>
Editing
53 items were found. Tab back to navigate through them. 
/ 
Navigator is ready 
  * [ AVFoundation ](https://developer.apple.com/documentation/avfoundation)
  * [ Additional data capture ](https://developer.apple.com/documentation/avfoundation/additional-data-capture)
  * [ Streaming depth data from the TrueDepth camera ](https://developer.apple.com/documentation/avfoundation/streaming-depth-data-from-the-truedepth-camera)
  *     * [ Additional data capture ](https://developer.apple.com/documentation/avfoundation/additional-data-capture)
    * Streaming depth data from the TrueDepth camera 


Sample Code
# Streaming depth data from the TrueDepth camera
Visualize depth data in 2D and 3D from the TrueDepth camera.
[ Download ](https://docs-assets.developer.apple.com/published/1bc13e22cdde/StreamingDepthDataFromTheTrueDepthCamera.zip)
iOS 12.0+iPadOS 12.0+Xcode 16.0+
## [Overview](https://developer.apple.com/documentation/avfoundation/streaming-depth-data-from-the-truedepth-camera#Overview)
The TrueDepth camera provides depth data in real time that allows you to determine the distance of a pixel from the front-facing camera. This sample demonstrates how to use the AVFoundation framework’s capture API to read data from the TrueDepth camera, and how to display it in an intuitive fashion onscreen.
The sample shows two different views: a 2D view that distinguishes depth values by mapping depth to color, and a 3D view that renders data as a point cloud.
To see this sample app in action, build and run the project in Xcode on an iOS device running iOS 11 or later. Because Xcode doesn’t have access to the TrueDepth camera, this sample will not build or run in the Xcode simulator.
### [Set up a capture session](https://developer.apple.com/documentation/avfoundation/streaming-depth-data-from-the-truedepth-camera#Set-up-a-capture-session)
Set up an `AVCaptureSession` on a separate thread via the session queue. Initialize this session queue before configuring the camera for capture, like so:
```
private let sessionQueue = DispatchQueue(label: "session queue", attributes: [], autoreleaseFrequency: .workItem)

```

The `startRunning` method is a blocking call that may take time to execute. Dispatch session setup to the session queue so the main queue isn’t blocked, allowing the app’s UI to stay responsive:
```
sessionQueue.async {
    self.configureSession()
}

```

Setting up the camera for video capture follows many of the same steps as normal video capture. See [Setting up a capture session](https://developer.apple.com/documentation/avfoundation/setting-up-a-capture-session) for details on configuring streaming setup.
On top of normal setup, request depth data by declaring a separate output:
```
private let depthDataOutput = AVCaptureDepthDataOutput()

```

Explicitly add this output type to your capture session:
```
session.addOutput(depthDataOutput)
depthDataOutput.isFilteringEnabled = false
if let connection = depthDataOutput.connection(with: .depthData) {
    connection.isEnabled = true
} else {
    print("No AVCaptureConnection")
}

```

Search for the highest resolution available with floating-point depth values, and lock the configuration to the format.
```
let depthFormats = videoDevice.activeFormat.supportedDepthDataFormats
let filtered = depthFormats.filter({
    CMFormatDescriptionGetMediaSubType($0.formatDescription) == kCVPixelFormatType_DepthFloat16
})
let selectedFormat = filtered.max(by: {
    first, second in CMVideoFormatDescriptionGetDimensions(first.formatDescription).width < CMVideoFormatDescriptionGetDimensions(second.formatDescription).width
})


do {
    try videoDevice.lockForConfiguration()
    videoDevice.activeDepthDataFormat = selectedFormat
    videoDevice.unlockForConfiguration()
} catch {
    print("Could not lock device for configuration: \(error)")
    setupResult = .configurationFailed
    session.commitConfiguration()
    return
}

```

Synchronize the normal RGB video data with depth data output. The first output in the `dataOutputs` array is the master output.
```
outputSynchronizer = AVCaptureDataOutputSynchronizer(dataOutputs: [videoDataOutput, depthDataOutput])
outputSynchronizer!.setDelegate(self, queue: dataOutputQueue)

```

The `CameraViewController` implementation creates and manages this session to interface with the camera. It also contains UI to toggle between the two viewing modes, 2D and 3D.
### [Visualize depth data in 2D](https://developer.apple.com/documentation/avfoundation/streaming-depth-data-from-the-truedepth-camera#Visualize-depth-data-in-2D)
The sample uses JET color coding to distinguish depth values, ranging from red (close) to blue (far). A slider controls the blending of the color code and the actual color values. Touching a pixel displays its depth value.
`DepthToJETConverter` performs the conversion. It separates the color spectrum into histogram bins, colors a Metal texture from depth values obtained in the image buffer, and renders that texture into the preview.
```
var cvTextureOut: CVMetalTexture?
CVMetalTextureCacheCreateTextureFromImage(kCFAllocatorDefault, textureCache, pixelBuffer, nil, textureFormat, width, height, 0, &cvTextureOut)
guard let cvTexture = cvTextureOut, let texture = CVMetalTextureGetTexture(cvTexture) else {
    print("Depth converter failed to create preview texture")
    CVMetalTextureCacheFlush(textureCache, 0)
    return nil
}

```

### [Visualize depth data in 3D](https://developer.apple.com/documentation/avfoundation/streaming-depth-data-from-the-truedepth-camera#Visualize-depth-data-in-3D)
The sample’s 3D viewer renders data as a point cloud. Control the camera with the following gestures:
  * Pinch to zoom.
  * Pan to move the camera around the center.
  * Rotate with two fingers to turn the camera angle.
  * Double-tap the screen to reset the initial position.


The sample implements a 3D point cloud as a `PointCloudMetalView`. It uses a Metal vertex shader to control geometry and a Metal fragment shader to color individual vertices, keeping the depth texture and color texture separate:
```
CVMetalTextureCacheRef _depthTextureCache;
CVMetalTextureCacheRef _colorTextureCache;

```

The depth frame’s depth map provides the basis for the Metal view’s depth texture:
```
CVPixelBufferRef depthFrame = depthData.depthDataMap;
CVMetalTextureRef cvDepthTexture = nullptr;
if (kCVReturnSuccess != CVMetalTextureCacheCreateTextureFromImage(kCFAllocatorDefault,
                        _depthTextureCache,
                        depthFrame,
                        nil,
                        MTLPixelFormatR16Float,
                        CVPixelBufferGetWidth(depthFrame),
                        CVPixelBufferGetHeight(depthFrame),
                        0,
                        &cvDepthTexture)) {
    NSLog(@"Failed to create depth texture");
    CVPixelBufferRelease(colorFrame);
    return;
}


id<MTLTexture> depthTexture = CVMetalTextureGetTexture(cvDepthTexture);

```

The RGB image provides the basis for the Metal view’s color texture:
```
CVMetalTextureRef cvColorTexture = nullptr;
if (kCVReturnSuccess != CVMetalTextureCacheCreateTextureFromImage(kCFAllocatorDefault,
                        _colorTextureCache,
                        colorFrame,
                        nil,
                        MTLPixelFormatBGRA8Unorm,
                        CVPixelBufferGetWidth(colorFrame),
                        CVPixelBufferGetHeight(colorFrame),
                        0,
                        &cvColorTexture)) {
    NSLog(@"Failed to create color texture");
    CVPixelBufferRelease(colorFrame);
    return;
}


id<MTLTexture> colorTexture = CVMetalTextureGetTexture(cvColorTexture);

```

### [Track thermal state](https://developer.apple.com/documentation/avfoundation/streaming-depth-data-from-the-truedepth-camera#Track-thermal-state)
Processing depth data from a live stream may cause the device to heat up. Keep tabs on the thermal state so you can alert the user if it exceeds a dangerous threshold.
```
@objc
func thermalStateChanged(notification: NSNotification) {
    if let processInfo = notification.object as? ProcessInfo {
        showThermalState(state: processInfo.thermalState)
    }
}


func showThermalState(state: ProcessInfo.ThermalState) {
    DispatchQueue.main.async {
        var thermalStateString = "UNKNOWN"
        if state == .nominal {
            thermalStateString = "NOMINAL"
        } else if state == .fair {
            thermalStateString = "FAIR"
        } else if state == .serious {
            thermalStateString = "SERIOUS"
        } else if state == .critical {
            thermalStateString = "CRITICAL"
        }
        
        let message = NSLocalizedString("Thermal state: \(thermalStateString)", comment: "Alert message when thermal state has changed")
        let alertController = UIAlertController(title: "TrueDepthStreamer", message: message, preferredStyle: .alert)
        alertController.addAction(UIAlertAction(title: NSLocalizedString("OK", comment: "Alert OK button"), style: .cancel, handler: nil))
        self.present(alertController, animated: true, completion: nil)
    }
}

```

## [See Also](https://developer.apple.com/documentation/avfoundation/streaming-depth-data-from-the-truedepth-camera#see-also)
### [Depth data capture](https://developer.apple.com/documentation/avfoundation/streaming-depth-data-from-the-truedepth-camera#Depth-data-capture)
[Capturing photos with depth](https://developer.apple.com/documentation/avfoundation/capturing-photos-with-depth)
Get a depth map with a photo to create effects like the system camera’s Portrait mode (on compatible devices).
[Creating auxiliary depth data manually](https://developer.apple.com/documentation/avfoundation/creating-auxiliary-depth-data-manually)
Generate a depth image and attach it to your own image.
[Capturing depth using the LiDAR camera](https://developer.apple.com/documentation/avfoundation/capturing-depth-using-the-lidar-camera)
Access the LiDAR camera on supporting devices to capture precise depth data.
[AVCamFilter: Applying filters to a capture stream](https://developer.apple.com/documentation/avfoundation/avcamfilter-applying-filters-to-a-capture-stream)
Render a capture stream with rose-colored filtering and depth effects.
[Enhancing live video by leveraging TrueDepth camera data](https://developer.apple.com/documentation/avfoundation/enhancing-live-video-by-leveraging-truedepth-camera-data)
Apply your own background to a live capture feed streamed from the front-facing TrueDepth camera.
[`class AVCaptureDepthDataOutput`](https://developer.apple.com/documentation/avfoundation/avcapturedepthdataoutput)
A capture output that records scene depth information on compatible camera devices.
[`class AVDepthData`](https://developer.apple.com/documentation/avfoundation/avdepthdata)
A container for per-pixel distance or disparity information captured by compatible camera devices.
[`class AVCameraCalibrationData`](https://developer.apple.com/documentation/avfoundation/avcameracalibrationdata)
Information about the camera characteristics used to capture images and depth data.
Current page is Streaming depth data from the TrueDepth camera 
[Apple](https://www.apple.com)
  1. [Developer](https://developer.apple.com/)
  2. [ Documentation ](https://developer.apple.com/documentation/)


###  Platforms 
Toggle Menu 
  * [iOS](https://developer.apple.com/ios/)
  * [iPadOS](https://developer.apple.com/ipados/)
  * [macOS](https://developer.apple.com/macos/)
  * [tvOS](https://developer.apple.com/tvos/)
  * [visionOS](https://developer.apple.com/visionos/)
  * [watchOS](https://developer.apple.com/watchos/)


###  Tools 
Toggle Menu 
  * [Swift](https://developer.apple.com/swift/)
  * [SwiftUI](https://developer.apple.com/swiftui/)
  * [Swift Playground](https://developer.apple.com/swift-playground/)
  * [TestFlight](https://developer.apple.com/testflight/)
  * [Xcode](https://developer.apple.com/xcode/)
  * [Xcode Cloud](https://developer.apple.com/xcode-cloud/)
  * [SF Symbols](https://developer.apple.com/sf-symbols/)


###  Topics & Technologies 
Toggle Menu 
  * [Accessibility](https://developer.apple.com/accessibility/)
  * [Accessories](https://developer.apple.com/accessories/)
  * [App Extension](https://developer.apple.com/app-extensions/)
  * [App Store](https://developer.apple.com/app-store/)
  * [Audio & Video](https://developer.apple.com/audio/)
  * [Augmented Reality](https://developer.apple.com/augmented-reality/)
  * [Design](https://developer.apple.com/design/)
  * [Distribution](https://developer.apple.com/distribute/)
  * [Education](https://developer.apple.com/education/)
  * [Fonts](https://developer.apple.com/fonts/)
  * [Games](https://developer.apple.com/games/)
  * [Health & Fitness](https://developer.apple.com/health-fitness/)
  * [In-App Purchase](https://developer.apple.com/in-app-purchase/)
  * [Localization](https://developer.apple.com/localization/)
  * [Maps & Location](https://developer.apple.com/maps/)
  * [Machine Learning & AI](https://developer.apple.com/machine-learning/)
  * [Open Source](https://opensource.apple.com/)
  * [Security](https://developer.apple.com/security/)
  * [Safari & Web](https://developer.apple.com/safari/)


###  Resources 
Toggle Menu 
  *   * [Documentation](https://developer.apple.com/documentation/)
  * [Tutorials](https://developer.apple.com/learn/)
  * [Downloads](https://developer.apple.com/download/)
  * [Forums](https://developer.apple.com/forums/)
  * [Videos](https://developer.apple.com/videos/)


###  Support 
Toggle Menu 
  * [Support Articles](https://developer.apple.com/support/articles/)
  * [Contact Us](https://developer.apple.com/contact/)
  * [Bug Reporting](https://developer.apple.com/bug-reporting/)
  * [System Status](https://developer.apple.com/system-status/)


###  Account 
Toggle Menu 
  * [Apple Developer](https://developer.apple.com/account/)
  * [App Store Connect](https://appstoreconnect.apple.com/)
  * [Certificates, IDs, & Profiles](https://developer.apple.com/account/ios/certificate/)
  * [Feedback Assistant](https://feedbackassistant.apple.com/)


###  Programs 
Toggle Menu 
  * [Apple Developer Program](https://developer.apple.com/programs/)
  * [Apple Developer Enterprise Program](https://developer.apple.com/programs/enterprise/)
  * [App Store Small Business Program](https://developer.apple.com/app-store/small-business-program/)
  * [MFi Program](https://mfi.apple.com/)
  * [News Partner Program](https://developer.apple.com/programs/news-partner/)
  * [Video Partner Program](https://developer.apple.com/programs/video-partner/)
  * [Security Bounty Program](https://developer.apple.com/security-bounty/)
  * [Security Research Device Program](https://developer.apple.com/programs/security-research-device/)


###  Events 
Toggle Menu 
  * [Meet with Apple](https://developer.apple.com/events/)
  * [Apple Developer Centers](https://developer.apple.com/events/developer-centers/)
  * [App Store Awards](https://developer.apple.com/app-store/app-store-awards/)
  * [Apple Design Awards](https://developer.apple.com/design/awards/)
  * [Apple Developer Academies](https://developer.apple.com/academies/)
  * [WWDC](https://developer.apple.com/wwdc/)


To submit feedback on documentation, visit [Feedback Assistant](applefeedback://new?form_identifier=developertools.fba&answers%5B%3Aarea%5D=seedADC%3Adevpubs&answers%5B%3Adoc_type_req%5D=Technology%20Documentation&answers%5B%3Adocumentation_link_req%5D=https%3A%2F%2Fdeveloper.apple.com%2Fdocumentation%2Favfoundation%2Fstreaming-depth-data-from-the-truedepth-camera).
Select a color scheme preference
Light
Dark
Auto
Copyright © 2025 [Apple Inc.](https://www.apple.com) All rights reserved. 
[ Terms of Use ](https://www.apple.com/legal/internet-services/terms/site.html)[ Privacy Policy ](https://www.apple.com/legal/privacy/)[ Agreements and Guidelines ](https://developer.apple.com/support/terms/)
