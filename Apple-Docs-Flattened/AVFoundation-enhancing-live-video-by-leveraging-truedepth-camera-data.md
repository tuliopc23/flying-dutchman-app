Source: https://developer.apple.com/documentation/avfoundation/enhancing-live-video-by-leveraging-truedepth-camera-data

[ Skip Navigation ](https://developer.apple.com/documentation/avfoundation/enhancing-live-video-by-leveraging-truedepth-camera-data#app-main)
  * [Global Nav Open Menu](https://developer.apple.com/documentation/avfoundation/enhancing-live-video-by-leveraging-truedepth-camera-data#ac-gn-menustate)[Global Nav Close Menu](https://developer.apple.com/documentation/avfoundation/enhancing-live-video-by-leveraging-truedepth-camera-data)
  * [Apple Developer](https://developer.apple.com/)


[ Search Developer Cancel  ](https://developer.apple.com/search/)
  * [Apple Developer](https://developer.apple.com/)
  * [News](https://developer.apple.com/news/)
  * [Discover](https://developer.apple.com/discover/)
  * [Design](https://developer.apple.com/design/)
  * [Develop](https://developer.apple.com/develop/)
  * [Distribute](https://developer.apple.com/distribute/)
  * [Support](https://developer.apple.com/support/)
  * [Account](https://developer.apple.com/account/)
  * [](https://developer.apple.com/search/)


Cancel 
Only search within “Documentation”
### Quick Links
  * [Downloads](https://developer.apple.com/download/)
  * [Documentation](https://developer.apple.com/documentation/)
  * [Sample Code](https://developer.apple.com/documentation/samplecode/)
  * [Videos](https://developer.apple.com/videos/)
  * [Forums](https://developer.apple.com/forums/)

5 Quick Links
[ Documentation ](https://developer.apple.com/documentation)
[ Open Menu ](https://developer.apple.com/documentation/avfoundation/enhancing-live-video-by-leveraging-truedepth-camera-data)
  * SwiftLanguage: Swift


[](https://developer.apple.com/documentation/avfoundation/enhancing-live-video-by-leveraging-truedepth-camera-data)
## [ AVFoundation  ](https://developer.apple.com/documentation/avfoundation)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
17 of 22 symbols inside 2121978169 containing 8 symbols[AVCaptureDataOutputSynchronizer](https://developer.apple.com/documentation/avfoundation/avcapturedataoutputsynchronizer)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
Collection
18 of 31 symbols inside <root> containing 22 symbols[Additional data capture](https://developer.apple.com/documentation/avfoundation/additional-data-capture)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
Collection
18 of 31 symbols inside <root> containing 22 symbols[Additional data capture](https://developer.apple.com/documentation/avfoundation/additional-data-capture)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
1 of 22 symbols inside 2121978169 
Depth data capture
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
2 of 22 symbols inside 2121978169 [Capturing photos with depth](https://developer.apple.com/documentation/avfoundation/capturing-photos-with-depth)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
3 of 22 symbols inside 2121978169 [Creating auxiliary depth data manually](https://developer.apple.com/documentation/avfoundation/creating-auxiliary-depth-data-manually)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
4 of 22 symbols inside 2121978169 [Capturing depth using the LiDAR camera](https://developer.apple.com/documentation/avfoundation/capturing-depth-using-the-lidar-camera)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
5 of 22 symbols inside 2121978169 [AVCamFilter: Applying filters to a capture stream](https://developer.apple.com/documentation/avfoundation/avcamfilter-applying-filters-to-a-capture-stream)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
6 of 22 symbols inside 2121978169 [Streaming depth data from the TrueDepth camera](https://developer.apple.com/documentation/avfoundation/streaming-depth-data-from-the-truedepth-camera)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
7 of 22 symbols inside 2121978169 [Enhancing live video by leveraging TrueDepth camera data](https://developer.apple.com/documentation/avfoundation/enhancing-live-video-by-leveraging-truedepth-camera-data)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
8 of 22 symbols inside 2121978169 containing 10 symbols[AVCaptureDepthDataOutput](https://developer.apple.com/documentation/avfoundation/avcapturedepthdataoutput)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
9 of 22 symbols inside 2121978169 containing 19 symbols[AVDepthData](https://developer.apple.com/documentation/avfoundation/avdepthdata)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
10 of 22 symbols inside 2121978169 containing 9 symbols[AVCameraCalibrationData](https://developer.apple.com/documentation/avfoundation/avcameracalibrationdata)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
11 of 22 symbols inside 2121978169 
Metadata capture
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
12 of 22 symbols inside 2121978169 containing 4 symbols[AVCaptureMetadataInput](https://developer.apple.com/documentation/avfoundation/avcapturemetadatainput)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
13 of 22 symbols inside 2121978169 containing 12 symbols[AVCaptureMetadataOutput](https://developer.apple.com/documentation/avfoundation/avcapturemetadataoutput)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
14 of 22 symbols inside 2121978169 containing 10 symbols[AVMetadataObject](https://developer.apple.com/documentation/avfoundation/avmetadataobject)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
Collection
15 of 22 symbols inside 2121978169 containing 15 symbols[Metadata types](https://developer.apple.com/documentation/avfoundation/metadata-types)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
16 of 22 symbols inside 2121978169 
Synchronized capture
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
17 of 22 symbols inside 2121978169 containing 8 symbols[AVCaptureDataOutputSynchronizer](https://developer.apple.com/documentation/avfoundation/avcapturedataoutputsynchronizer)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
18 of 22 symbols inside 2121978169 containing 4 symbols[AVCaptureSynchronizedDataCollection](https://developer.apple.com/documentation/avfoundation/avcapturesynchronizeddatacollection)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
19 of 22 symbols inside 2121978169 containing 5 symbols[AVCaptureSynchronizedSampleBufferData](https://developer.apple.com/documentation/avfoundation/avcapturesynchronizedsamplebufferdata)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
20 of 22 symbols inside 2121978169 containing 2 symbols[AVCaptureSynchronizedMetadataObjectData](https://developer.apple.com/documentation/avfoundation/avcapturesynchronizedmetadataobjectdata)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
21 of 22 symbols inside 2121978169 containing 5 symbols[AVCaptureSynchronizedDepthData](https://developer.apple.com/documentation/avfoundation/avcapturesynchronizeddepthdata)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
C
22 of 22 symbols inside 2121978169 containing 2 symbols[AVCaptureSynchronizedData](https://developer.apple.com/documentation/avfoundation/avcapturesynchronizeddata)
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
19 of 31 symbols inside <root>
Editing
To navigate the symbols, press Up Arrow, Down Arrow, Left Arrow or Right Arrow 
Collection
20 of 31 symbols inside <root> containing 7 symbols[Composite assets](https://developer.apple.com/documentation/avfoundation/composite-assets)
53 items were found. Tab back to navigate through them. 
/ 
Navigator is ready 
  * [ AVFoundation ](https://developer.apple.com/documentation/avfoundation)
  * [ Additional data capture ](https://developer.apple.com/documentation/avfoundation/additional-data-capture)
  * [ Enhancing live video by leveraging TrueDepth camera data ](https://developer.apple.com/documentation/avfoundation/enhancing-live-video-by-leveraging-truedepth-camera-data)
  *     * [ Additional data capture ](https://developer.apple.com/documentation/avfoundation/additional-data-capture)
    * Enhancing live video by leveraging TrueDepth camera data 


Sample Code
# Enhancing live video by leveraging TrueDepth camera data
Apply your own background to a live capture feed streamed from the front-facing TrueDepth camera.
[ Download ](https://docs-assets.developer.apple.com/published/3cc4556ec9ec/EnhancingLiveVideoByLeveragingTrueDepthCameraData.zip)
iOS 12.0+iPadOS 12.0+Xcode 16.0+
## [Overview](https://developer.apple.com/documentation/avfoundation/enhancing-live-video-by-leveraging-truedepth-camera-data#Overview)
The TrueDepth camera provides real-time depth data that allows you to segment foreground from background in a video feed.
This sample app leverages depth data to dynamically replace the entire background with a custom image. It then performs Gaussian filtering and other image processing operations to remove holes and smooth the effect.
### [Preview the sample app](https://developer.apple.com/documentation/avfoundation/enhancing-live-video-by-leveraging-truedepth-camera-data#Preview-the-sample-app)
To see this sample app in action, build and run the project in Xcode on a device running iOS 11 or later. Because Xcode doesn’t have access to the TrueDepth camera, this sample won’t work in the Xcode simulator.
The sample app begins by removing the background, replacing it with black. Apply your own image from the camera roll by swiping down anywhere on the video feed.
### [Set up live capture from the TrueDepth camera](https://developer.apple.com/documentation/avfoundation/enhancing-live-video-by-leveraging-truedepth-camera-data#Set-up-live-capture-from-the-TrueDepth-camera)
Set up an [`AVCaptureSession`](https://developer.apple.com/documentation/avfoundation/avcapturesession) on a separate thread via the session queue. Initialize this session queue before configuring the camera for capture.
```
// Communicate with the session and other session objects on this queue.
private let sessionQueue = DispatchQueue(label: "session queue", attributes: [], autoreleaseFrequency: .workItem)

```

The [`startRunning()`](https://developer.apple.com/documentation/avfoundation/avcapturesession/startrunning\(\)) method is a blocking call which can take a long time. Dispatch session setup to the sessionQueue so the main queue isn’t blocked, allowing the app’s UI to stay responsive.
```
sessionQueue.async {
    self.configureSession()
}

```

Setting up the camera for video capture follows many of the same steps as normal video capture. See [Setting up a capture session](https://developer.apple.com/documentation/avfoundation/setting-up-a-capture-session) for details on configuring streaming setup.
On top of normal setup, request depth data by declaring a separate output:
```
private let depthDataOutput = AVCaptureDepthDataOutput()

```

Explicitly add this output type to your capture session:
```
if session.canAddOutput(depthDataOutput) {
    session.addOutput(depthDataOutput)
    depthDataOutput.isFilteringEnabled = true
    if let connection = depthDataOutput.connection(with: .depthData) {
        connection.isEnabled = true
    } else {
        print("No AVCaptureConnection")
    }
} else {
    print("Could not add depth data output to the session")
    setupResult = .configurationFailed
    session.commitConfiguration()
    return
}

```

Search for the highest resolution available with floating-point depth values, and lock the configuration to the format.
```
let depthFormats = videoDevice.activeFormat.supportedDepthDataFormats
let depth32formats = depthFormats.filter({
    CMFormatDescriptionGetMediaSubType($0.formatDescription) == kCVPixelFormatType_DepthFloat32
})
if depth32formats.isEmpty {
    print("Device does not support Float32 depth format")
    setupResult = .configurationFailed
    session.commitConfiguration()
    return
}


let selectedFormat = depth32formats.max(by: { first, second in
    CMVideoFormatDescriptionGetDimensions(first.formatDescription).width <
        CMVideoFormatDescriptionGetDimensions(second.formatDescription).width })

```

Synchronize the normal RGB video data with depth data output. The first output in the dataOutputs array is the master output.
```
outputSynchronizer = AVCaptureDataOutputSynchronizer(dataOutputs: [videoDataOutput, depthDataOutput, metadataOutput])
outputSynchronizer!.setDelegate(self, queue: dataOutputQueue)

```

### [Create a binary foreground mask](https://developer.apple.com/documentation/avfoundation/enhancing-live-video-by-leveraging-truedepth-camera-data#Create-a-binary-foreground-mask)
Assume the foreground to be a human face. You can accomplish face detection through the Vision framework’s [`VNDetectFaceRectanglesRequest`](https://developer.apple.com/documentation/Vision/VNDetectFaceRectanglesRequest), but this sample doesn’t need anything else from Vision, so it’s simpler to consult the [`AVMetadataObject`](https://developer.apple.com/documentation/avfoundation/avmetadataobject) for [`face`](https://developer.apple.com/documentation/avfoundation/avmetadataobject/objecttype/face).
```
self.session.addOutput(metadataOutput)
if metadataOutput.availableMetadataObjectTypes.contains(.face) {
    metadataOutput.metadataObjectTypes = [.face]
}

```

Using the [`AVMetadataObject`](https://developer.apple.com/documentation/avfoundation/avmetadataobject), locate the face’s bounding box and center. Assume there is only one face and take the first one in the metadata object.
```
if let syncedMetaData: AVCaptureSynchronizedMetadataObjectData =
    synchronizedDataCollection.synchronizedData(for: metadataOutput) as? AVCaptureSynchronizedMetadataObjectData,
    let firstFace = syncedMetaData.metadataObjects.first,
    let connection = self.videoDataOutput.connection(with: AVMediaType.video),
    let face = videoDataOutput.transformedMetadataObject(for: firstFace, connection: connection) {
    let faceCenter = CGPoint(x: face.bounds.midX, y: face.bounds.midY)

```

Depth maps differ from their normal camera image counterparts in resolution; as a result, normal image coordinates differ from depth map coordinates by a scale factor. Compute the scale factor and transform the face’s center to depth map coordinates.
```
let scaleFactor = CGFloat(CVPixelBufferGetWidth(depthPixelBuffer)) / CGFloat(CVPixelBufferGetWidth(videoPixelBuffer))
let pixelX = Int((faceCenter.x * scaleFactor).rounded())
let pixelY = Int((faceCenter.y * scaleFactor).rounded())

```

Once you have the face in depth map coordinates, threshold the image to create a binary mask image, where the foreground pixels are `1`, and the background pixels are `0`.
```
let depthWidth = CVPixelBufferGetWidth(depthPixelBuffer)
let depthHeight = CVPixelBufferGetHeight(depthPixelBuffer)


CVPixelBufferLockBaseAddress(depthPixelBuffer, CVPixelBufferLockFlags(rawValue: 0))


for yMap in 0 ..< depthHeight {
    let rowData = CVPixelBufferGetBaseAddress(depthPixelBuffer)! + yMap * CVPixelBufferGetBytesPerRow(depthPixelBuffer)
    let data = UnsafeMutableBufferPointer<Float32>(start: rowData.assumingMemoryBound(to: Float32.self), count: depthWidth)
    for index in 0 ..< depthWidth {
        if data[index] > 0 && data[index] <= depthCutOff {
            data[index] = 1.0
        } else {
            data[index] = 0.0
        }
    }
}

```

### [Smooth the depth mask with Core Image filters](https://developer.apple.com/documentation/avfoundation/enhancing-live-video-by-leveraging-truedepth-camera-data#Smooth-the-depth-mask-with-Core-Image-filters)
The depth map doesn’t share the RGB image’s sharp resolution, so the mask may contain holes along the interface between foreground and background. Once you have a downsampled mask image, use a Gaussian filter to smooth out the holes, so the interface doesn’t look jagged or pixelated. Clamp your image before filtering it, and crop it afterward, so it retains the proper size when applied with the original image.
```
let depthMaskImage = CIImage(cvPixelBuffer: depthPixelBuffer, options: [:])


// Smooth edges to create an alpha matte, then upscale it to the RGB resolution.
let alphaUpscaleFactor = Float(CVPixelBufferGetWidth(videoPixelBuffer)) / Float(depthWidth)
let alphaMatte = depthMaskImage.clampedToExtent()
    .applyingFilter("CIGaussianBlur", parameters: ["inputRadius": blurRadius])
    .applyingFilter("CIGammaAdjust", parameters: ["inputPower": gamma])
    .cropped(to: depthMaskImage.extent)
    .applyingFilter("CIBicubicScaleTransform", parameters: ["inputScale": alphaUpscaleFactor])

```

The parameters of your `CIGaussianBlur` and `CIGammaAdjust` filters directly affect the smoothness of the edge pixels. You can tune the blur and smoothness by adjusting the Gaussian blur filter’s input radius, as well as the gamma adjustment filter’s input power.
![Graph showing the effect of fine-tuning Gaussian blur and Gamma adjustment](https://docs-assets.developer.apple.com/published/d9c978332af648b441769594e26efc66/graph.png)
### [Blend foreground and background with the alpha matte](https://developer.apple.com/documentation/avfoundation/enhancing-live-video-by-leveraging-truedepth-camera-data#Blend-foreground-and-background-with-the-alpha-matte)
The final step is applying your filtered smooth binary mask to the input video frame.
Because you’ve performed image processing in Core Image using the `CIGaussianBlur` and `CIGammaAdjust` filters, it’s most computationally efficient to apply the resulting mask in Core Image, as well. That means converting your video from [CVPixelBuffer](https://developer.apple.com/documentation/CoreVideo/cvpixelbuffer-q2e) format to [`CIImage`](https://developer.apple.com/documentation/CoreImage/CIImage) format, allowing you to apply the alpha matte to the original image, and blend in your custom background image with the `CIBlendWithMask` filter.
```
let image = CIImage(cvPixelBuffer: videoPixelBuffer)


// Apply alpha matte to the video.
var parameters = ["inputMaskImage": alphaMatte]
if let background = self.backgroundImage {
    parameters["inputBackgroundImage"] = background
}


let output = image.applyingFilter("CIBlendWithMask", parameters: parameters)

```

Update your preview to display the final composited image onscreen.
```
previewView.image = output

```

## [See Also](https://developer.apple.com/documentation/avfoundation/enhancing-live-video-by-leveraging-truedepth-camera-data#see-also)
### [Depth data capture](https://developer.apple.com/documentation/avfoundation/enhancing-live-video-by-leveraging-truedepth-camera-data#Depth-data-capture)
[Capturing photos with depth](https://developer.apple.com/documentation/avfoundation/capturing-photos-with-depth)
Get a depth map with a photo to create effects like the system camera’s Portrait mode (on compatible devices).
[Creating auxiliary depth data manually](https://developer.apple.com/documentation/avfoundation/creating-auxiliary-depth-data-manually)
Generate a depth image and attach it to your own image.
[Capturing depth using the LiDAR camera](https://developer.apple.com/documentation/avfoundation/capturing-depth-using-the-lidar-camera)
Access the LiDAR camera on supporting devices to capture precise depth data.
[AVCamFilter: Applying filters to a capture stream](https://developer.apple.com/documentation/avfoundation/avcamfilter-applying-filters-to-a-capture-stream)
Render a capture stream with rose-colored filtering and depth effects.
[Streaming depth data from the TrueDepth camera](https://developer.apple.com/documentation/avfoundation/streaming-depth-data-from-the-truedepth-camera)
Visualize depth data in 2D and 3D from the TrueDepth camera.
[`class AVCaptureDepthDataOutput`](https://developer.apple.com/documentation/avfoundation/avcapturedepthdataoutput)
A capture output that records scene depth information on compatible camera devices.
[`class AVDepthData`](https://developer.apple.com/documentation/avfoundation/avdepthdata)
A container for per-pixel distance or disparity information captured by compatible camera devices.
[`class AVCameraCalibrationData`](https://developer.apple.com/documentation/avfoundation/avcameracalibrationdata)
Information about the camera characteristics used to capture images and depth data.
Current page is Enhancing live video by leveraging TrueDepth camera data 
[Apple](https://www.apple.com)
  1. [Developer](https://developer.apple.com/)
  2. [ Documentation ](https://developer.apple.com/documentation/)


###  Platforms 
Toggle Menu 
  * [iOS](https://developer.apple.com/ios/)
  * [iPadOS](https://developer.apple.com/ipados/)
  * [macOS](https://developer.apple.com/macos/)
  * [tvOS](https://developer.apple.com/tvos/)
  * [visionOS](https://developer.apple.com/visionos/)
  * [watchOS](https://developer.apple.com/watchos/)


###  Tools 
Toggle Menu 
  * [Swift](https://developer.apple.com/swift/)
  * [SwiftUI](https://developer.apple.com/swiftui/)
  * [Swift Playground](https://developer.apple.com/swift-playground/)
  * [TestFlight](https://developer.apple.com/testflight/)
  * [Xcode](https://developer.apple.com/xcode/)
  * [Xcode Cloud](https://developer.apple.com/xcode-cloud/)
  * [SF Symbols](https://developer.apple.com/sf-symbols/)


###  Topics & Technologies 
Toggle Menu 
  * [Accessibility](https://developer.apple.com/accessibility/)
  * [Accessories](https://developer.apple.com/accessories/)
  * [App Extension](https://developer.apple.com/app-extensions/)
  * [App Store](https://developer.apple.com/app-store/)
  * [Audio & Video](https://developer.apple.com/audio/)
  * [Augmented Reality](https://developer.apple.com/augmented-reality/)
  * [Design](https://developer.apple.com/design/)
  * [Distribution](https://developer.apple.com/distribute/)
  * [Education](https://developer.apple.com/education/)
  * [Fonts](https://developer.apple.com/fonts/)
  * [Games](https://developer.apple.com/games/)
  * [Health & Fitness](https://developer.apple.com/health-fitness/)
  * [In-App Purchase](https://developer.apple.com/in-app-purchase/)
  * [Localization](https://developer.apple.com/localization/)
  * [Maps & Location](https://developer.apple.com/maps/)
  * [Machine Learning & AI](https://developer.apple.com/machine-learning/)
  * [Open Source](https://opensource.apple.com/)
  * [Security](https://developer.apple.com/security/)
  * [Safari & Web](https://developer.apple.com/safari/)


###  Resources 
Toggle Menu 
  *   * [Documentation](https://developer.apple.com/documentation/)
  * [Tutorials](https://developer.apple.com/learn/)
  * [Downloads](https://developer.apple.com/download/)
  * [Forums](https://developer.apple.com/forums/)
  * [Videos](https://developer.apple.com/videos/)


###  Support 
Toggle Menu 
  * [Support Articles](https://developer.apple.com/support/articles/)
  * [Contact Us](https://developer.apple.com/contact/)
  * [Bug Reporting](https://developer.apple.com/bug-reporting/)
  * [System Status](https://developer.apple.com/system-status/)


###  Account 
Toggle Menu 
  * [Apple Developer](https://developer.apple.com/account/)
  * [App Store Connect](https://appstoreconnect.apple.com/)
  * [Certificates, IDs, & Profiles](https://developer.apple.com/account/ios/certificate/)
  * [Feedback Assistant](https://feedbackassistant.apple.com/)


###  Programs 
Toggle Menu 
  * [Apple Developer Program](https://developer.apple.com/programs/)
  * [Apple Developer Enterprise Program](https://developer.apple.com/programs/enterprise/)
  * [App Store Small Business Program](https://developer.apple.com/app-store/small-business-program/)
  * [MFi Program](https://mfi.apple.com/)
  * [News Partner Program](https://developer.apple.com/programs/news-partner/)
  * [Video Partner Program](https://developer.apple.com/programs/video-partner/)
  * [Security Bounty Program](https://developer.apple.com/security-bounty/)
  * [Security Research Device Program](https://developer.apple.com/programs/security-research-device/)


###  Events 
Toggle Menu 
  * [Meet with Apple](https://developer.apple.com/events/)
  * [Apple Developer Centers](https://developer.apple.com/events/developer-centers/)
  * [App Store Awards](https://developer.apple.com/app-store/app-store-awards/)
  * [Apple Design Awards](https://developer.apple.com/design/awards/)
  * [Apple Developer Academies](https://developer.apple.com/academies/)
  * [WWDC](https://developer.apple.com/wwdc/)


To submit feedback on documentation, visit [Feedback Assistant](applefeedback://new?form_identifier=developertools.fba&answers%5B%3Aarea%5D=seedADC%3Adevpubs&answers%5B%3Adoc_type_req%5D=Technology%20Documentation&answers%5B%3Adocumentation_link_req%5D=https%3A%2F%2Fdeveloper.apple.com%2Fdocumentation%2Favfoundation%2Fenhancing-live-video-by-leveraging-truedepth-camera-data).
Select a color scheme preference
Light
Dark
Auto
Copyright © 2025 [Apple Inc.](https://www.apple.com) All rights reserved. 
[ Terms of Use ](https://www.apple.com/legal/internet-services/terms/site.html)[ Privacy Policy ](https://www.apple.com/legal/privacy/)[ Agreements and Guidelines ](https://developer.apple.com/support/terms/)
